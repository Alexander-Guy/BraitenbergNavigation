{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s0zmqjwFCnKZ"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.linalg.linalg as LA\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.transforms import Affine2D\n",
    "import matplotlib.patches as patches\n",
    "from matplotlib.text import Annotation\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "import math\n",
    "import random\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from scipy.spatial import ConvexHull, convex_hull_plot_2d\n",
    "from scipy.spatial.distance import euclidean\n",
    "import scipy.stats as stats\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "twoPi = np.pi * 2\n",
    "\n",
    "def find(condition):\n",
    "    res, = np.nonzero(np.ravel(condition))\n",
    "    return res\n",
    "\n",
    "class MultipleNRV(object):\n",
    "    \"\"\"Multiple independent normal random variables.\"\"\"\n",
    "    def __init__(self, size, loc=0., scale=1.):\n",
    "        self.size = size\n",
    "        self.mean, self.std = loc, scale\n",
    "        self.twoVariance = 2 * self.std ** 2\n",
    "    \n",
    "    def pdf(self, xs):\n",
    "        \"\"\"Returns the probability density function value for a particular\n",
    "        vector.\"\"\"\n",
    "        twoVar = self.twoVariance\n",
    "        if twoVar == 0:\n",
    "            return 1 if xs == self.mean else 0\n",
    "        else:\n",
    "            delta2 = (xs - self.mean) ** 2\n",
    "            return np.product( np.exp( -delta2 / twoVar ) / np.sqrt( twoVar * np.pi) )        \n",
    "            \n",
    "    def sample(self):\n",
    "        \"\"\"Returns a vector sampled from the PDF.\"\"\"\n",
    "        loc, scale, n = self.mean, self.std, self.size\n",
    "        return loc if scale == 0 else np.random.normal(loc, scale, size=self.size)                                                                        \n",
    "\n",
    "class World(object):\n",
    "    \n",
    "    def __init__(self, sensor_angles=(0,), luminance=1.0, light_coords=(10, 0, -0.1), v_max=1.0, agent_radius=0.5, sensor_noise=0.12, motor_noise=0.25, dt=0.1, seed=None):\n",
    "\n",
    "        self.sensors = np.array(sensor_angles)\n",
    "        self.light_pos = np.array(light_coords)\n",
    "        self.v_max = v_max\n",
    "        self.agent_radius = agent_radius\n",
    "        self.luminance = luminance\n",
    "        self.dt = dt\n",
    "        \n",
    "        if seed is not None:\n",
    "            np.random.seed(seed)\n",
    "\n",
    "        # set up noise random variables\n",
    "        sensor_sigma = sensor_noise * np.sqrt(dt)\n",
    "        motor_sigma = motor_noise * np.sqrt(dt)\n",
    "        self.sensor_rv = MultipleNRV(size=len(sensor_angles), scale = sensor_sigma)\n",
    "        self.motor_rv = MultipleNRV(size=2, scale = motor_sigma)\n",
    "                \n",
    "    def sensor_pos(self, state):\n",
    "        \"\"\"Returns an array corresponding to a list of (x, y, 0) sensor \n",
    "        positions in world coordinates.\"\"\"\n",
    "        sensors, r = self.sensors, self.agent_radius\n",
    "        x, y, theta = state\n",
    "        n = len(sensors)\n",
    "        \n",
    "        result = np.zeros( (n, 3) )\n",
    "        # copy robot x, y into sensors\n",
    "        result[:,0:2] = state[0:2]\n",
    "        \n",
    "        angles = theta + sensors\n",
    "        result[:,0] = r * np.cos(angles) + x\n",
    "        result[:,1] = r * np.sin(angles) + y\n",
    "        \n",
    "        return result\n",
    "        \n",
    "    def sensor_input(self, state):\n",
    "        \"\"\"Returns an array of raw sensor input values for a particular\n",
    "        agent state (position and orientation). These are calculated\n",
    "        according to an inverse square distance law, and the agent's body\n",
    "        can occlude a sensor reducing its input to zero.\n",
    "        \"\"\"        \n",
    "        # various relevant parameters\n",
    "        r, K = self.agent_radius, self.luminance\n",
    "        # light position\n",
    "        l_pos = self.light_pos        \n",
    "\n",
    "        # unpack 3D position and heading from (x, y, theta) state\n",
    "        pos, theta = np.array(tuple(state[0:2]) + (0,)), state[-1]        \n",
    "\n",
    "        # positions in world coordinates of each sensor\n",
    "        s_pos = self.sensor_pos(state)\n",
    "        # array of distances of sensors from light source\n",
    "        d_s = LA.norm(l_pos - s_pos, axis=1)\n",
    "        \n",
    "        # distance of light from robot's centre\n",
    "        d_0 = LA.norm(l_pos - pos)\n",
    "\n",
    "        # array of zeros or ones for each sensor according to whether the \n",
    "        # agent's body lies between the sensor and the light source\n",
    "        not_occluded = (d_0**2 >= r**2 >= (d_s**2 - d_0**2))\n",
    "        \n",
    "        # light reaching each sensor\n",
    "        return not_occluded * K / d_s **2                \n",
    "        \n",
    "    def sensor_transform(self, activation):\n",
    "        \"\"\"Returns a vector of sensor readings for a particular sensor input \n",
    "        value (activation) vector. Noise is usually applied to the activation \n",
    "        before applying the transform.\"\"\"\n",
    "        # rescale to (0, 1) interval, assuming activation is positive\n",
    "        #return activation / (1 + activation)\n",
    "        K, l_pos = self.luminance, self.light_pos\n",
    "        # minimum distance is z coordinate of the light position\n",
    "        d_min = l_pos[-1]\n",
    "        \n",
    "        # rescale activation to range between 0 and a_max\n",
    "        # with midpoint around \n",
    "        a_max = K / ( d_min ** 2 )\n",
    "        a = a_max / (1 + np.exp(5*(K/4 - activation)))\n",
    "        \n",
    "        #return 1 / (1 + np.exp(-activation))\n",
    "        return activation\n",
    "        #return np.sqrt(K / a)\n",
    "    \n",
    "    def sensor_inverse_transform(self, reading):\n",
    "        \"\"\"Returns the vector of sensor input values (activations) that would be \n",
    "        needed to produce the specified sensor reading. \"\"\"\n",
    "        return reading / (1 - reading)\n",
    "    \n",
    "    \n",
    "    def sense(self, state):\n",
    "        \"\"\"Returns a vector of sensor reading values for a \n",
    "        particular agent state (position and orientation). \n",
    "        Noise is added to the raw luminance at the sensor's location\n",
    "        and the result is rescaled to the (0, 1) interval.\n",
    "        \"\"\"\n",
    "        activation = self.sensor_input(state) + self.sensor_rv.sample()\n",
    "                        \n",
    "        # and rescale to (0, 1) interval\n",
    "        return self.sensor_transform(activation)\n",
    "    \n",
    "    def p_sensation(self, state, sensation):\n",
    "        \"\"\"Returns a probability density value for the likelihood of a \n",
    "        particular sensor reading vector given a particular agent state.\"\"\"\n",
    "        # invert rescaling operation to find the original activations \n",
    "        sensor_activation = self.sensor_inverse_transform(sensation)\n",
    "        # determine the actual luminance at the sensors\n",
    "        sensor_input = self.sensor_input(state)        \n",
    "        \n",
    "        # interrogate the RV object to get the PDF value\n",
    "        return self.sensor_rv.pdf(sensor_input - sensor_activation)        \n",
    "\n",
    "    def act(self, state, action):\n",
    "        \"\"\"Applies a motor activation vector to an agent state, and simulates \n",
    "        the consequences using Euler integration over a dt interval.\"\"\"\n",
    "        # noisily map the action values to a (-1, +1) interval\n",
    "        motor_out = self.v_max * np.tanh(action) + self.motor_rv.sample()\n",
    "        \n",
    "        # calculate the linear speed and angular speed\n",
    "        v = motor_out.mean()\n",
    "        omega = (motor_out[1] - motor_out[0]) / (2.0 * self.agent_radius)\n",
    "        \n",
    "        # calculate time derivative of state\n",
    "        theta = state[-1]\n",
    "        deriv = [ v * np.cos(theta), v * np.sin(theta), omega ]\n",
    "        \n",
    "        # perform Euler integration\n",
    "        return self.dt * np.array(deriv) + state \n",
    "    \n",
    "    # Function for changing the light position, here we can take the light, move it for N timestamps (in this case 100 or 10 seconds) and move it back\n",
    "    def light_change(self,original_state,active_token,stamp,light_poses):\n",
    "        \n",
    "        if active_token == 2: # If the token given is 2 initially we won't get a light change\n",
    "            pass\n",
    "        \n",
    "        if active_token == 0: # change light from its intiailised location to a random point along the x=10 axis, as it was found, too far away from the light,t he robot will nto get distracted\n",
    "            original_state = self.light_pos # initialisied light location for replacement\n",
    "            light_coords = [10,random.uniform(-5,5),-0.1]\n",
    "            self.light_pos = np.array(light_coords) # officially change light position in simulation\n",
    "            new_active_token = 1 #change token for next round\n",
    "            light_poses.append(light_coords) # add new coordinates to light locations\n",
    "\n",
    "            \n",
    "        if active_token == 1: # if the light had been moved here we move the light back to its initialised location\n",
    "            self.light_pos = original_state # officially change light location in code\n",
    "            new_active_token = 0 # change our token back\n",
    "            self.luminance = 1 \n",
    "\n",
    "        stamp = stamp + 100\n",
    "            \n",
    "        return(original_state,new_active_token,stamp,light_poses,self.light_pos)        \n",
    "        \n",
    "    def simulate(self, controller,active_token, interval=500.0):\n",
    "        \"\"\"Simulates the agent-environment system for the specified interval\n",
    "        (in simulated time units) starting from a random state. Returns\n",
    "        a (poses, sensations, actions, states) tuple where poses is a time array \n",
    "        of agent poses (position and orientation), sensations is a time array of \n",
    "        sensory readings, actions is a time array of motor activations, and\n",
    "        states is a list of arbitrary internal controller state objects.\n",
    "        \n",
    "        Must be called with a controller function of the form \n",
    "        controller(sensation, state, dt) that returns a (action, state) tuple\n",
    "        outputting motor activations and updated internal state in\n",
    "        response to sensor readings.\n",
    "        \"\"\"\n",
    "        poses = [ self.random_state() ]\n",
    "\n",
    "        states = [ None ]\n",
    "        sensations = [ ]\n",
    "        actions = [ ]\n",
    "        \n",
    "        motor_history =   []         # Robot keeps track of its own motor positions\n",
    "        local_angle_history  =   [0] # Initialise local angle history\n",
    "        global_angle_history =   [0] # Initialise global angle history \n",
    "                                     # (all of this is relative to the journey of the robot and thus the starrt angles arent important)\n",
    "        slope_l = []                 # List of graients found by the light to attempt to tell if the robot has found the most\n",
    "                                     # light intensity for a given angle\n",
    "        \n",
    "\n",
    "        self_location   = [[0,0]] # Here we need to define where the robot thinks it starts, \n",
    "                                  # it doesnt matter if it actually starts at say [1,1] \n",
    "                                  #all that matters is where it thinks its location RELATIVE to its start position\n",
    "        target_angle    = 0\n",
    "        sense_list      = []\n",
    "        \n",
    "        reached = 0               # Tokens that the robot can change if it deems it has found the light or home\n",
    "        reached_home = 0\n",
    "\n",
    "     \n",
    "        original_state = self.light_pos # make sure that the intialised location can be founda gain by the light movement function\n",
    "        \n",
    "        light_poses = [] # if we choose to change the light location, this keeps track of teh new location for plotting\n",
    "        \n",
    "        stamp = 0 # this gives us a timestamp that the light can be in it's temporary location for before reverting back to its original\n",
    "                  # position\n",
    "        \n",
    "        for i in range(int( interval / self.dt )):\n",
    "            \n",
    "            if i%1000 == 0 and active_token == 0: # here every 100 seconds the light will move \n",
    "                original_state,active_token,stamp,light_poses,self.light_pos = self.light_change(original_state,active_token,i,light_poses)\n",
    "                \n",
    "            if stamp == i  and active_token == 1: # here we call and move the light back when the allotted decoy time is up\n",
    "                original_state,active_token,stamp,light_poses,self.light_pos = self.light_change(original_state,active_token,i,light_poses)\n",
    "\n",
    "            sensations.append(self.sense(poses[-1]))\n",
    "            action, local_angle_history,self_location,global_angle_history,reached,reached_home,slope_l,state = controller(sensations, states[-1], self.dt,motor_history,local_angle_history,self_location,target_angle,global_angle_history,reached,reached_home,slope_l)     \n",
    "            actions.append(action)\n",
    "            states.append(state)\n",
    "            poses.append(self.act(poses[-1], actions[-1]))\n",
    "\n",
    "        return np.array(poses), np.array(sensations), np.array(actions), states,self.light_pos,light_poses,self_location \n",
    "        \n",
    "    def random_state(self):\n",
    "        \"\"\"Returns a random initial state.\"\"\"\n",
    "        result = np.zeros(3)\n",
    "        result[-1] = np.random.rand() * twoPi\n",
    "        \n",
    "        return result\n",
    "        \n",
    "        \n",
    "    def task1fitness(self, poses):\n",
    "        \"\"\"Returns the fitness of the trajectory described by poses on \n",
    "        assignment task 1 (reaching the light source).\"\"\"\n",
    "        return -self.reached_light_at(poses)\n",
    "        \n",
    "    def task2fitness(self, poses):\n",
    "        \"\"\"Returns the fitness of the trajectory described by poses on \n",
    "        assignment task 1 (reaching the light source and returning to base).\"\"\"\n",
    "        light_time = self.reached_light_at(poses)\n",
    "        if light_time == np.inf:\n",
    "            return -np.inf\n",
    "        return -self.first_reached(poses, np.array([0, 0]), after=light_time) \n",
    "        \n",
    "    def first_reached(self, poses, xy, after = 0, within = 1.5):\n",
    "        after_index = int(np.floor(after / self.dt))\n",
    "        ds = LA.norm(xy - poses[after_index:,0:2], axis=1)\n",
    "        indices = np.nonzero(ds < within)[0]\n",
    "        \n",
    "        if len(indices) == 0:\n",
    "            return np.inf\n",
    "        \n",
    "        return (indices[0] + after_index) * self.dt\n",
    "        \n",
    "    def reached_light_at(self, poses):\n",
    "        return self.first_reached(poses, self.light_pos[0:2])\n",
    "    \n",
    "    \n",
    "    def animate(self, poses, sensations, speedup=5):\n",
    "        r, l_pos = self.agent_radius, self.light_pos\n",
    "        x, y, theta = poses[0]\n",
    "        \n",
    "        # use an Ellipse to visually represent the agent's body\n",
    "        body = patches.Ellipse(xy=(0, 0), width=2 * r, height=2 * r, fc='w', ec='k')\n",
    "        # use a black dot to visually represent each sensor\n",
    "        sensors = [ patches.Ellipse(xy=(r * np.cos(theta), r * np.sin(theta)), width=0.2, height=0.2, fc='b') for theta in self.sensors ]\n",
    "        # use small rectangles to visually represent the motors\n",
    "        motors = [ patches.Rectangle((-0.5*r, y), width = r, height = 0.2*r, color=\"black\") for y in (-1.1*r, 0.9*r) ]\n",
    "        # use a line to indicate the agent's orientation\n",
    "        line = Line2D( (x, x + r * np.cos(theta)), (y, y + r * np.sin(theta)) )\n",
    "        line = Line2D( (0, r), (0, 0) )\n",
    "        # draw a line showing the agent's \"trail\"\n",
    "        trail = Line2D( [], [], color='r') \n",
    "        # display a clock\n",
    "        clock = Annotation('', (0.8, 0.9), xycoords='axes fraction')    \n",
    "        # use a yellow circle to visually represent the light\n",
    "        light_r = patches.Ellipse(xy=l_pos[0:2], width=1, height=1, fc='y', ec='none')\n",
    "        light = patches.Ellipse(xy=l_pos[0:2], width=0.25, height=0.25, fc='b')\n",
    "        \n",
    "        fig, (ax1, ax2) = plt.subplots(2, 1, gridspec_kw = {'height_ratios': [10, 1] } )\n",
    "        ax1.axis(\"equal\")\n",
    "        ax1.set_xlim([-15, 15])\n",
    "        ax1.set_ylim([-15, 15])\n",
    "        ax1.set_title(\"Click On Main Display To Pause / Unpause\")\n",
    "        \n",
    "        ax2.set_title(\"Click On Sensor Graph To Change Time\")\n",
    "        \n",
    "        tracker = ax2.axvline(0, 0, 1)\n",
    "        paused = [ False ]\n",
    "        last_index = [ -1 ]\n",
    "        t_index = [ 0 ]\n",
    "        \n",
    "        if sensations is not None:\n",
    "            times = np.arange(0, self.dt * len(sensations), self.dt)\n",
    "            # plot the sensor values\n",
    "            ax2.plot(times, sensations, 'k');\n",
    "            # plot the ideal (noiseless) sensor values\n",
    "            ideal = np.array([self.sensor_transform(self.sensor_input(pose)) for pose in poses[:-1]])\n",
    "            print(max(ideal[31:66-len(sensations)]))\n",
    "            ax2.plot(times, ideal, 'r')\n",
    "    \n",
    "        def draw(index):\n",
    "            if not paused[0]:\n",
    "                t_index[0] = t_index[0] + (index - last_index[0])\n",
    "                t_index[0] = t_index[0] % len(poses)\n",
    "    \n",
    "            last_index[0] = index\n",
    "                \n",
    "            x, y, theta = poses[t_index[0]]\n",
    "            tr = Affine2D().rotate(theta).translate(x, y) + ax1.transData\n",
    "            \n",
    "            agent_patches = (body, line) + tuple(sensors) + tuple(motors)\n",
    "            \n",
    "            for patch in agent_patches:\n",
    "                patch.set_transform(tr);\n",
    "                \n",
    "            trail.set_data( poses[:t_index[0], 0], poses[:t_index[0], 1] )\n",
    "            \n",
    "            time = t_index[0] * self.dt\n",
    "            tracker.set_xdata([time, time])\n",
    "                \n",
    "            clock.set_text(\"Time: %.02f\" % time)\n",
    "                    \n",
    "            return (trail, light_r, light, clock, tracker) + agent_patches\n",
    "        \n",
    "        def init():\n",
    "            result = draw(0)\n",
    "            for artist in result:\n",
    "                if artist is not tracker:\n",
    "                    ax1.add_artist(artist)\n",
    "            return result\n",
    "    \n",
    "        def onclick(event):\n",
    "            if event.button == 1:\n",
    "                # pause if the user clicks on the main figure\n",
    "                if event.inaxes is ax1:\n",
    "                    paused[0] = not paused[0]\n",
    "                # edit time directly if the user clicks on the graph over time\n",
    "                elif event.inaxes is ax2:\n",
    "                    t_index[0] = (int) (event.xdata / self.dt)            \n",
    "            \n",
    "        def anim(index):\n",
    "            return draw(index)\n",
    "        \n",
    "        \n",
    "        ani = FuncAnimation(fig, anim, init_func=init, frames = None, interval=1000*self.dt/speedup, blit=True, save_count=len(poses))\n",
    "        \n",
    "        plt.show()\n",
    "    \n",
    "        fig.canvas.mpl_connect('button_press_event', onclick)\n",
    " \n",
    "        return ani            \n",
    "                                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# This function defines the circulatiry of a set of coordinates, the more circular a path, the more aimless\n",
    "# a search strategy appeasr to be, thus circularity is a good measure of purpose (or lack thereof)\n",
    "\n",
    "def circul(x,y,graph):\n",
    "\n",
    "    def x_y_tuple(x,y):\n",
    "        list_coords_tuple = []\n",
    "        for i in range(len(x)):\n",
    "            list_coords_tuple.append([x[i], y[i]])\n",
    "        return(list_coords_tuple)\n",
    "\n",
    "    def perim(points,graph):\n",
    "        hull = ConvexHull(points)\n",
    "        if graph ==1 :\n",
    "            plt.plot(points[:,0], points[:,1], 'o')\n",
    "            for simplex in hull.simplices:\n",
    "                plt.plot(points[simplex, 0], points[simplex, 1], 'r')\n",
    "        perimeter = hull.area\n",
    "        return(perimeter)\n",
    "    \n",
    "    def area_cal(pts):\n",
    "        hull = ConvexHull(pts) \n",
    "        area = hull.volume\n",
    "        return(area)\n",
    "    \n",
    "    pts = np.array(x_y_tuple(x,y))\n",
    "    perimeter = perim(pts,graph)\n",
    "    area = area_cal(pts)\n",
    "\n",
    "    circularity = 4*math.pi*area/((perimeter**2))\n",
    "    \n",
    "    return(area, perimeter, circularity)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def BTDR_Gradient(sensations_list, state, dt,motor_history,local_angle_history,self_location,target_angle,global_angle_history,reached,reached_home,slope_l):\n",
    "    \n",
    "    #here we can pick the sampling rate, for one full rotation it is about 31-31 timesteps so we will be safe and say 31\n",
    "    \n",
    "    sampling_size = 31\n",
    "    \n",
    "    if len(sensations_list) <= sampling_size: # so to get an idea of the sensor noise (standard deviation for the gaussian curve)\n",
    "                                              # lets sit in place for 31 timesteps and see what sensor variation we get\n",
    "        output = [0,0] \n",
    "        slope = 0 # we are going to say that the slope information is 0 because wee need a minimum of 31 sample size of our sense\n",
    "                  # data to get a graient with the code implemented, besides as this is noise determining behaviour, slope isnt important right now\n",
    "                \n",
    "    if len(sensations_list)>sampling_size:# okay now we have obtained sensory noise lets calculate the slope\n",
    "        \n",
    "        sensations_snip = (np.array(sensations_list[-sampling_size:])).reshape(sampling_size,)\n",
    "    \n",
    "        slope, intercept, r_value, p_value, std_err = stats.linregress(np.linspace(0,sampling_size,sampling_size),sensations_snip)\n",
    "        std = np.std(sensations_list[:sampling_size])\n",
    "        \n",
    "        # Here, the slope or gradient is used to integrate proior information to create a more informed threshold value for our 'Run' behaviour\n",
    "        \n",
    "        output = [1,-1] # lets 'Tumbele' and look for the angle ascosiated with the sharpest sensory gradient\n",
    "\n",
    "        counter = 0 # set a counter for our sampling\n",
    "        sense_max = -100 # set a sensory reading lower than possible \n",
    "        index_max = 0 # token that keeps track of highest gradient timestep in past 31\n",
    "        \n",
    "        for i in range(sampling_size-1): # 'Tumble'for one full rotation\n",
    "\n",
    "            if slope_l[-sampling_size:][i] >= sense_max: # If our gradient is high enough this will become the new timestamp to change our angle\n",
    "                sense_max = slope_l[-sampling_size:][i]  # change the maximum gradient value to comapre against \n",
    "                \n",
    "                index_max = counter # counter to hold onto the local timestamp\n",
    "\n",
    "            counter+=1 # move onto next timestamp\n",
    "         \n",
    "        target_angle = local_angle_history[-sampling_size:][index_max]\n",
    "        \n",
    "\n",
    "    angle_change = ((np.tanh(output[1])-np.tanh(output[0]))/(2*0.5)) # We update a local angle set as if we would keep spinning indefinitely, this allows us to make the choise to wither go forward or spin\n",
    "    new_angle = local_angle_history[-1] + angle_change*dt            # update the local angle history\n",
    "      \n",
    "        \n",
    "    if target_angle+0.75 >new_angle >target_angle-0.75 and len(sensations_list)>2*sampling_size:\n",
    "        output = [1,1] # if the theoretical next (local) angle matches the target angle derived above we move toward the light source\n",
    "\n",
    "    if reached == 1: # if the light source is percieved as reached we change our behaviour \n",
    "                \n",
    "        net_angle = ((global_angle_history[-1])%(2*math.pi)) # here we are finding the angle of orientation of the robot (where its front is facing)\n",
    "        home_angle = abs(np.arctan(self_location[-1][1]/self_location[-1][0]))# here we are finding the angle of the centre of the robot chissis is relative to its percieved start points\n",
    "        \n",
    "        if self_location[-1][1] >= 0 and  self_location[-1][0] > 0: # decide what angle we need to turn to to be facing home\n",
    "            targ = math.pi + home_angle\n",
    "            \n",
    "        if self_location[-1][1] < 0 and  self_location[-1][0] < 0:\n",
    "            targ = home_angle\n",
    "        \n",
    "        if self_location[-1][1] > 0 and  self_location[-1][0] < 0:\n",
    "            targ = 2*math.pi - home_angle\n",
    "            \n",
    "        if self_location[-1][1] < 0 and  self_location[-1][0] > 0:\n",
    "            targ = math.pi - home_angle\n",
    "        \n",
    "        if targ*1.1 > net_angle > targ*0.9:\n",
    "            output = [1,1] # lets head home\n",
    "                               \n",
    "        if targ*1.1 < net_angle or net_angle < targ*0.9:\n",
    "            output = [0,1]# let's turn around and face home based on above information\n",
    "        \n",
    "        \n",
    "        if 0.5>output[0]>-0.5 and 0.5>output[1]>-0.5:\n",
    "            reached_home = 1 # if we percieve ourr cordinates are approximately zero lets change the 'reached home token'\n",
    "\n",
    "\n",
    "            \n",
    "    if reached_home == 1:\n",
    "   # if we have decided we have reached home lets shut off motors (this never happens in practice)\n",
    "\n",
    "        output =[0,0]\n",
    "    \n",
    "    if len(sensations_list) > sampling_size and slope>0.025:\n",
    "        reached = 1\n",
    "    \n",
    "    delta_angle = ((np.tanh(output[1])-np.tanh(output[0]))/(2*0.5))# this notes the actual change in angle (instead of th etheoretical perpetual rotation we note what out motor outputs did)\n",
    "\n",
    "    real_new_angle = global_angle_history[-1] + delta_angle*dt # euler integrate our new angle\n",
    "    \n",
    "    hyp = (((np.tanh(output[1])+np.tanh(output[0]))/2)) # find out our journey linkage (how far we moved in this time step)\n",
    "\n",
    "    s_location = [(hyp*(np.cos(real_new_angle))*dt + self_location[-1][0]),(hyp*(np.sin(real_new_angle))*dt + self_location[-1][1])]\n",
    "    self_location.append(s_location) # lets integrate our knowledge of angle and journey linkage to update our idea of self location\n",
    "\n",
    "    local_angle_history.append(new_angle)\n",
    "    global_angle_history.append(real_new_angle) # update our angle history\n",
    "    \n",
    "    slope_l.append(slope) # update our list of gradient\n",
    "\n",
    "\n",
    "    return(output,local_angle_history,self_location,global_angle_history,reached,reached_home,slope_l,None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01106674]\n",
      "Fitness on task 1: -438.100000\n",
      "Fitness on task 2: -inf\n"
     ]
    }
   ],
   "source": [
    "# Do a trial run to see if everything works\n",
    "\n",
    "w = World(sensor_noise=0.5,motor_noise=0.5)\n",
    "\n",
    "act_token = 2\n",
    "\n",
    "poses, sensations, actions, states,light_pos,light_poses,self_location = w.simulate(BTDR_Gradient,active_token=act_token)\n",
    "self_location=np.array(self_location)\n",
    "plt.ion()\n",
    "%matplotlib qt\n",
    "\n",
    "# Lets plot our outward and return jounrney ant style with our path integrated route home\n",
    "\n",
    "if np.isinf(w.task1fitness(poses)) ==True:\n",
    "    plt.plot(poses[:,0],poses[:,1],label = 'Outward Journey')\n",
    "    \n",
    "else:\n",
    "    plt.plot(poses[:int(-w.task1fitness(poses)*10)][:,0], poses[:int(-w.task1fitness(poses)*10)][:,1],c='b',label = 'Outward Journey')\n",
    "    plt.plot(poses[int(-w.task1fitness(poses)*10):][:,0], poses[int(-w.task1fitness(poses)*10):][:,1],c='r',label = 'Return Journey')\n",
    "\n",
    "if len(light_poses)>0:\n",
    "    plt.scatter((np.array(light_poses))[:,0],(np.array(light_poses))[:,1],c='y',label='decoy light')\n",
    "plt.scatter(light_pos[0], light_pos[1],c='r',s=100,label = 'Final_light')\n",
    "\n",
    "circ_num =circul(poses[:,0],poses[:,1],0)\n",
    "\n",
    "\n",
    "plt.title('Bacterial tumbling and dead reckoning (light gradient) \\n , path of robot  Circularity = '+str(round(circ_num[2],3)))\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "if act_token == 0:\n",
    "    str1 = 'Bacterial tumbling and dead reckoning (light gradient)  controller with decoys, path of robot'\n",
    "    \n",
    "if act_token == 2:\n",
    "    str1 = 'Bacterial tumbling and dead reckoning (light gradient)  controller without decoys, path of robot'\n",
    "    \n",
    "if np.isinf(w.task1fitness(poses)) == False and np.isinf(w.task2fitness(poses)) == False:\n",
    "    str2 = 'success'\n",
    "    \n",
    "else:\n",
    "    str2 = 'Failure'\n",
    "plt.savefig(str1+str2)\n",
    "\n",
    "ani = w.animate(poses, sensations)\n",
    "\n",
    "print(\"Fitness on task 1: %f\" % w.task1fitness(poses))\n",
    "print(\"Fitness on task 2: %f\" % w.task2fitness(poses))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we can run the simulation many times to get a pcolor plot of successes with different levels of noise with \n",
    "# or without decoy lights\n",
    "\n",
    "def test_func(act_token):\n",
    "    \n",
    "    res = 20\n",
    "    \n",
    "    sens_vars = np.linspace(0.1,1,res)\n",
    "    mot_vars = np.linspace(0.1,1,res)\n",
    "    \n",
    "    results_outward =np.zeros((res,res))\n",
    "    results_return =np.zeros((res,res))\n",
    "\n",
    "    k = 0\n",
    "    for s in sens_vars:\n",
    "        l = 0 \n",
    "        for m in mot_vars:\n",
    "            w = World(sensor_noise =s,motor_noise=m)\n",
    "            \n",
    "            avg_o = 0\n",
    "            avg_r = 0\n",
    "            \n",
    "            for i in range(5):\n",
    "                \n",
    "                poses, sensations, actions,light_pos,light_poses,light_poses,self_location = w.simulate(BTDR_Gradient,active_token=act_token)\n",
    "                fit_1 = w.task1fitness(poses)\n",
    "                fit_2 = w.task2fitness(poses)\n",
    "    \n",
    "                if np.isinf(fit_1)==True:\n",
    "                    fit_1 = -1000\n",
    "                \n",
    "                if np.isinf(fit_2)==True:\n",
    "                    fit_2 = -1000\n",
    "                    \n",
    "                avg_r+=fit_2\n",
    "                avg_o+=fit_1\n",
    "                \n",
    "            results_outward[k][l] = avg_o/5\n",
    "            results_return[k][l] = avg_r/5\n",
    "            \n",
    "            l+=1\n",
    "        k+=1 \n",
    "        clear_output()\n",
    "        print(k*100/(res),'% Complete')\n",
    "        \n",
    "\n",
    "    \n",
    "    fig, (ax0,ax1) = plt.subplots(1,2)\n",
    "\n",
    "    c = ax0.pcolor(sens_vars,mot_vars,results_outward, cmap='RdBu')\n",
    "    ax0.set_title('Outward journey successes')\n",
    "    ax0.set_xlabel('Motor Noise')\n",
    "    ax0.set_ylabel('Sensor Noise')\n",
    "    ax0.axis([0.1, 1, 0.1, 1])\n",
    "    fig.colorbar(c , ax=ax0)\n",
    "            \n",
    "    c = ax1.pcolor(sens_vars,mot_vars,results_return, cmap='RdBu')\n",
    "    ax1.set_title('Return journey successes')\n",
    "    ax1.set_xlabel('Motor Noise')\n",
    "    ax1.set_ylabel('Sensor Noise')\n",
    "    ax1.axis([0.1, 1, 0.1, 1])\n",
    "    fig.colorbar(c , ax=ax1)\n",
    "    \n",
    "    if act_token == 0 :\n",
    "        fig.suptitle('Bacterial tumbling with dead reckoning  (light gradient) \\n performance (w/ Decoy light)')\n",
    "        fig.savefig('Bacterialtumblingwithdeadreckoning(lightgradient)performance(wDecoylight).PNG')\n",
    "    if act_token == 2 :\n",
    "        fig.suptitle('Bacterial tumbling with dead reckoning  (light gradient) \\n  performance (No decoy light)')\n",
    "        fig.savefig('Bacterialtumblingwithdeadreckoning(lightgradient)performance(NoDecoylight).PNG')\n",
    "\n",
    "test_func(0)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Mapping_controller_no_path_integration.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
