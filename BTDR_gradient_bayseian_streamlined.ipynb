{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s0zmqjwFCnKZ"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.linalg.linalg as LA\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.transforms import Affine2D\n",
    "import matplotlib.patches as patches\n",
    "from matplotlib.text import Annotation\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "\n",
    "import random\n",
    "from IPython.display import clear_output\n",
    "import math\n",
    "\n",
    "import scipy.stats as stats\n",
    "from scipy.spatial import ConvexHull, convex_hull_plot_2d\n",
    "from scipy.spatial.distance import euclidean\n",
    "from scipy.optimize import leastsq\n",
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "twoPi = np.pi * 2\n",
    "\n",
    "def find(condition):\n",
    "    res, = np.nonzero(np.ravel(condition))\n",
    "    return res\n",
    "\n",
    "class MultipleNRV(object):\n",
    "    \"\"\"Multiple independent normal random variables.\"\"\"\n",
    "    def __init__(self, size, loc=0., scale=1.):\n",
    "        self.size = size\n",
    "        self.mean, self.std = loc, scale\n",
    "        self.twoVariance = 2 * self.std ** 2\n",
    "    \n",
    "    def pdf(self, xs):\n",
    "        \"\"\"Returns the probability density function value for a particular\n",
    "        vector.\"\"\"\n",
    "        twoVar = self.twoVariance\n",
    "        if twoVar == 0:\n",
    "            return 1 if xs == self.mean else 0\n",
    "        else:\n",
    "            delta2 = (xs - self.mean) ** 2\n",
    "            return np.product( np.exp( -delta2 / twoVar ) / np.sqrt( twoVar * np.pi) )        \n",
    "            \n",
    "    def sample(self):\n",
    "        \"\"\"Returns a vector sampled from the PDF.\"\"\"\n",
    "        loc, scale, n = self.mean, self.std, self.size\n",
    "        return loc if scale == 0 else np.random.normal(loc, scale, size=self.size)                                                                        \n",
    "\n",
    "class World(object):\n",
    "    \n",
    "    def __init__(self, sensor_angles=(0,), luminance=1.0, light_coords=(10,0, -0.1), v_max=1.0, agent_radius=0.5, sensor_noise=0.12, motor_noise=0.25, dt=0.1, seed=None):\n",
    "\n",
    "        self.sensors = np.array(sensor_angles)\n",
    "        self.light_pos = np.array(light_coords)\n",
    "        self.v_max = v_max\n",
    "        self.agent_radius = agent_radius\n",
    "        self.luminance = luminance\n",
    "        self.dt = dt\n",
    "        \n",
    "        if seed is not None:\n",
    "            np.random.seed(seed)\n",
    "\n",
    "        # set up noise random variables\n",
    "        sensor_sigma = sensor_noise * np.sqrt(dt)\n",
    "        motor_sigma = motor_noise * np.sqrt(dt)\n",
    "        self.sensor_rv = MultipleNRV(size=len(sensor_angles), scale = sensor_sigma)\n",
    "        self.motor_rv = MultipleNRV(size=2, scale = motor_sigma)\n",
    "                \n",
    "    def sensor_pos(self, state):\n",
    "        \"\"\"Returns an array corresponding to a list of (x, y, 0) sensor \n",
    "        positions in world coordinates.\"\"\"\n",
    "        sensors, r = self.sensors, self.agent_radius\n",
    "        x, y, theta = state\n",
    "        n = len(sensors)\n",
    "        \n",
    "        result = np.zeros( (n, 3) )\n",
    "        # copy robot x, y into sensors\n",
    "        result[:,0:2] = state[0:2]\n",
    "        \n",
    "        angles = theta + sensors\n",
    "        result[:,0] = r * np.cos(angles) + x\n",
    "        result[:,1] = r * np.sin(angles) + y\n",
    "        \n",
    "        return result\n",
    "        \n",
    "    def sensor_input(self, state):\n",
    "        \"\"\"Returns an array of raw sensor input values for a particular\n",
    "        agent state (position and orientation). These are calculated\n",
    "        according to an inverse square distance law, and the agent's body\n",
    "        can occlude a sensor reducing its input to zero.\n",
    "        \"\"\"        \n",
    "        # various relevant parameters\n",
    "        r, K = self.agent_radius, self.luminance\n",
    "        # light position\n",
    "        l_pos = self.light_pos        \n",
    "\n",
    "        # unpack 3D position and heading from (x, y, theta) state\n",
    "        pos, theta = np.array(tuple(state[0:2]) + (0,)), state[-1]        \n",
    "\n",
    "        # positions in world coordinates of each sensor\n",
    "        s_pos = self.sensor_pos(state)\n",
    "        # array of distances of sensors from light source\n",
    "        d_s = LA.norm(l_pos - s_pos, axis=1)\n",
    "        \n",
    "        # distance of light from robot's centre\n",
    "        d_0 = LA.norm(l_pos - pos)\n",
    "\n",
    "        # array of zeros or ones for each sensor according to whether the \n",
    "        # agent's body lies between the sensor and the light source\n",
    "        not_occluded = (d_0**2 >= r**2 >= (d_s**2 - d_0**2))\n",
    "        \n",
    "        # light reaching each sensor\n",
    "        return not_occluded * K / d_s **2                \n",
    "        \n",
    "    def sensor_transform(self, activation):\n",
    "        \"\"\"Returns a vector of sensor readings for a particular sensor input \n",
    "        value (activation) vector. Noise is usually applied to the activation \n",
    "        before applying the transform.\"\"\"\n",
    "        # rescale to (0, 1) interval, assuming activation is positive\n",
    "        #return activation / (1 + activation)\n",
    "        K, l_pos = self.luminance, self.light_pos\n",
    "        # minimum distance is z coordinate of the light position\n",
    "        d_min = l_pos[-1]\n",
    "        \n",
    "        # rescale activation to range between 0 and a_max\n",
    "        # with midpoint around \n",
    "        a_max = K / ( d_min ** 2 )\n",
    "        a = a_max / (1 + np.exp(5*(K/4 - activation)))\n",
    "        \n",
    "        #return 1 / (1 + np.exp(-activation))\n",
    "        return activation\n",
    "        #return np.sqrt(K / a)\n",
    "    \n",
    "    def sensor_inverse_transform(self, reading):\n",
    "        \"\"\"Returns the vector of sensor input values (activations) that would be \n",
    "        needed to produce the specified sensor reading. \"\"\"\n",
    "        return reading / (1 - reading)\n",
    "    \n",
    "    \n",
    "    def sense(self, state):\n",
    "        \"\"\"Returns a vector of sensor reading values for a \n",
    "        particular agent state (position and orientation). \n",
    "        Noise is added to the raw luminance at the sensor's location\n",
    "        and the result is rescaled to the (0, 1) interval.\n",
    "        \"\"\"\n",
    "        activation = self.sensor_input(state) + self.sensor_rv.sample()\n",
    "                        \n",
    "        # and rescale to (0, 1) interval\n",
    "        return self.sensor_transform(activation)\n",
    "    \n",
    "    def p_sensation(self, state, sensation):\n",
    "        \"\"\"Returns a probability density value for the likelihood of a \n",
    "        particular sensor reading vector given a particular agent state.\"\"\"\n",
    "        # invert rescaling operation to find the original activations \n",
    "        sensor_activation = self.sensor_inverse_transform(sensation)\n",
    "        # determine the actual luminance at the sensors\n",
    "        sensor_input = self.sensor_input(state)        \n",
    "        \n",
    "        # interrogate the RV object to get the PDF value\n",
    "        return self.sensor_rv.pdf(sensor_input - sensor_activation)        \n",
    "\n",
    "    def act(self, state, action):\n",
    "        \"\"\"Applies a motor activation vector to an agent state, and simulates \n",
    "        the consequences using Euler integration over a dt interval.\"\"\"\n",
    "        # noisily map the action values to a (-1, +1) interval\n",
    "        motor_out = self.v_max * np.tanh(action) + self.motor_rv.sample()\n",
    "        \n",
    "        # calculate the linear speed and angular speed\n",
    "        v = motor_out.mean()\n",
    "        omega = (motor_out[1] - motor_out[0]) / (2.0 * self.agent_radius)\n",
    "        \n",
    "        # calculate time derivative of state\n",
    "        theta = state[-1]\n",
    "        deriv = [ v * np.cos(theta), v * np.sin(theta), omega ]\n",
    "        \n",
    "        # perform Euler integration\n",
    "        return self.dt * np.array(deriv) + state \n",
    "    \n",
    "    \n",
    "    # Function for changing the light position, here we can take the light, move it for N timestamps (in this case 100 or 10 seconds) and move it back\n",
    "    def light_change(self,original_state,active_token,stamp,light_poses):\n",
    "        \n",
    "        if active_token == 2: # If the token given is 2 initially we won't get a light change\n",
    "            pass\n",
    "        \n",
    "        if active_token == 0: # change light from its intiailised location to a random point along the x=10 axis, as it was found, too far away from the light,t he robot will nto get distracted\n",
    "            original_state = self.light_pos # initialisied light location for replacement\n",
    "            light_coords = [10,random.uniform(-5,5),-0.1]\n",
    "            self.light_pos = np.array(light_coords) # officially change light position in simulation\n",
    "            new_active_token = 1 #change token for next round\n",
    "            light_poses.append(light_coords) # add new coordinates to light locations\n",
    "\n",
    "            \n",
    "        if active_token == 1: # if the light had been moved here we move the light back to its initialised location\n",
    "            self.light_pos = original_state # officially change light location in code\n",
    "            new_active_token = 0 # change our token back\n",
    "            self.luminance = 1 \n",
    "\n",
    "        stamp = stamp + 100\n",
    "            \n",
    "        return(original_state,new_active_token,stamp,light_poses,self.light_pos)        \n",
    "        \n",
    "    def simulate(self, controller,active_token, interval=500.0):\n",
    "        \"\"\"Simulates the agent-environment system for the specified interval\n",
    "        (in simulated time units) starting from a random state. Returns\n",
    "        a (poses, sensations, actions, states) tuple where poses is a time array \n",
    "        of agent poses (position and orientation), sensations is a time array of \n",
    "        sensory readings, actions is a time array of motor activations, and\n",
    "        states is a list of arbitrary internal controller state objects.\n",
    "        \n",
    "        Must be called with a controller function of the form \n",
    "        controller(sensation, state, dt) that returns a (action, state) tuple\n",
    "        outputting motor activations and updated internal state in\n",
    "        response to sensor readings.\n",
    "        \"\"\"\n",
    "        poses = [ self.random_state() ]\n",
    "\n",
    "        states = [ None ]\n",
    "        sensations = [ ]\n",
    "        actions = [ ]\n",
    "        \n",
    "        motor_history =   []         # Robot keeps track of its own motor positions\n",
    "        local_angle_history  =   [0] # Initialise local angle history\n",
    "        global_angle_history =   [0] # Initialise global angle history \n",
    "                                     # (all of this is relative to the journey of the robot and thus the starrt angles arent important)\n",
    "        slope_l = []                 # List of graients found by the light to attempt to tell if the robot has found the most\n",
    "                                     # light intensity for a given angle\n",
    "        \n",
    "\n",
    "        self_location   = [[0,0]] # Here we need to define where the robot thinks it starts, \n",
    "                                  # it doesnt matter if it actually starts at say [1,1] \n",
    "                                  #all that matters is where it thinks its location RELATIVE to its start position\n",
    "        target_angle    = 0\n",
    "        sense_list      = []    \n",
    "        \n",
    "        reached = 0               # Tokens that the robot can change if it deems it has found the light or home\n",
    "        reached_home = 0\n",
    "\n",
    "        \n",
    "        original_state = self.light_pos # make sure that the intialised location can be founda gain by the light movement function\n",
    "        \n",
    "        light_poses = [] # if we choose to change the light location, this keeps track of teh new location for plotting\n",
    "        \n",
    "        stamp = 0 # this gives us a timestamp that the light can be in it's temporary location for before reverting back to its original\n",
    "                  # position\n",
    "        \n",
    "        guess_angle = 0 # for the bayesian calculation, we need a guess of how far and at what angle the light is reletive to the robot, this variable is for the controller to process and pass\n",
    "        \n",
    "        for i in range(int( interval / self.dt )):\n",
    "            \n",
    "            if i%1000 == 0 and active_token == 0: # here every 100 seconds the light will move \n",
    "                original_state,active_token,stamp,light_poses,self.light_pos = self.light_change(original_state,active_token,i,light_poses)\n",
    "                \n",
    "            if stamp == i  and active_token == 1: # here we call and move the light back when the allotted decoy time is up\n",
    "                original_state,active_token,stamp,light_poses,self.light_pos = self.light_change(original_state,active_token,i,light_poses)\n",
    "\n",
    "            sensations.append(self.sense(poses[-1]))\n",
    "            action, local_angle_history,self_location,global_angle_history,reached,reached_home,slope_l,guess_angle,state = controller(sensations, states[-1], self.dt,motor_history,local_angle_history,self_location,target_angle,global_angle_history,reached,reached_home,slope_l,guess_angle)     \n",
    "            actions.append(action)\n",
    "            states.append(state)\n",
    "            poses.append(self.act(poses[-1], actions[-1]))\n",
    "\n",
    "        return np.array(poses), np.array(sensations), np.array(actions), states,self.light_pos,light_poses,self_location,guess_angle \n",
    "        \n",
    "    def random_state(self):\n",
    "        \"\"\"Returns a random initial state.\"\"\"\n",
    "        result = np.zeros(3)\n",
    "        result[-1] = np.random.rand() * twoPi\n",
    "        \n",
    "        return result\n",
    "        \n",
    "        \n",
    "    def task1fitness(self, poses):\n",
    "        \"\"\"Returns the fitness of the trajectory described by poses on \n",
    "        assignment task 1 (reaching the light source).\"\"\"\n",
    "        return -self.reached_light_at(poses)\n",
    "        \n",
    "    def task2fitness(self, poses):\n",
    "        \"\"\"Returns the fitness of the trajectory described by poses on \n",
    "        assignment task 1 (reaching the light source and returning to base).\"\"\"\n",
    "        light_time = self.reached_light_at(poses)\n",
    "        if light_time == np.inf:\n",
    "            return -np.inf\n",
    "        return -self.first_reached(poses, np.array([0, 0]), after=light_time) \n",
    "        \n",
    "    def first_reached(self, poses, xy, after = 0, within = 1.5):\n",
    "        after_index = int(np.floor(after / self.dt))\n",
    "        ds = LA.norm(xy - poses[after_index:,0:2], axis=1)\n",
    "        indices = np.nonzero(ds < within)[0]\n",
    "        \n",
    "        if len(indices) == 0:\n",
    "            return np.inf\n",
    "        \n",
    "        return (indices[0] + after_index) * self.dt\n",
    "        \n",
    "    def reached_light_at(self, poses):\n",
    "        return self.first_reached(poses, self.light_pos[0:2])\n",
    "    \n",
    "    \n",
    "    def animate(self, poses, sensations, speedup=5):\n",
    "        r, l_pos = self.agent_radius, self.light_pos\n",
    "        x, y, theta = poses[0]\n",
    "        \n",
    "        # use an Ellipse to visually represent the agent's body\n",
    "        body = patches.Ellipse(xy=(0, 0), width=2 * r, height=2 * r, fc='w', ec='k')\n",
    "        # use a black dot to visually represent each sensor\n",
    "        sensors = [ patches.Ellipse(xy=(r * np.cos(theta), r * np.sin(theta)), width=0.2, height=0.2, fc='b') for theta in self.sensors ]\n",
    "        # use small rectangles to visually represent the motors\n",
    "        motors = [ patches.Rectangle((-0.5*r, y), width = r, height = 0.2*r, color=\"black\") for y in (-1.1*r, 0.9*r) ]\n",
    "        # use a line to indicate the agent's orientation\n",
    "        line = Line2D( (x, x + r * np.cos(theta)), (y, y + r * np.sin(theta)) )\n",
    "        line = Line2D( (0, r), (0, 0) )\n",
    "        # draw a line showing the agent's \"trail\"\n",
    "        trail = Line2D( [], [], color='r') \n",
    "        # display a clock\n",
    "        clock = Annotation('', (0.8, 0.9), xycoords='axes fraction')    \n",
    "        # use a yellow circle to visually represent the light\n",
    "        light_r = patches.Ellipse(xy=l_pos[0:2], width=1, height=1, fc='y', ec='none')\n",
    "        light = patches.Ellipse(xy=l_pos[0:2], width=0.25, height=0.25, fc='b')\n",
    "        \n",
    "        fig, (ax1, ax2) = plt.subplots(2, 1, gridspec_kw = {'height_ratios': [10, 1] } )\n",
    "        ax1.axis(\"equal\")\n",
    "        ax1.set_xlim([-15, 15])\n",
    "        ax1.set_ylim([-15, 15])\n",
    "        ax1.set_title(\"Click On Main Display To Pause / Unpause\")\n",
    "        \n",
    "        ax2.set_title(\"Click On Sensor Graph To Change Time\")\n",
    "        \n",
    "        tracker = ax2.axvline(0, 0, 1)\n",
    "        paused = [ False ]\n",
    "        last_index = [ -1 ]\n",
    "        t_index = [ 0 ]\n",
    "        \n",
    "        if sensations is not None:\n",
    "            times = np.arange(0, self.dt * len(sensations), self.dt)\n",
    "            # plot the sensor values\n",
    "            ax2.plot(times, sensations, 'k');\n",
    "            # plot the ideal (noiseless) sensor values\n",
    "            ideal = np.array([self.sensor_transform(self.sensor_input(pose)) for pose in poses[:-1]])\n",
    "            print(ideal[0])\n",
    "            ax2.plot(times, ideal, 'r')\n",
    "    \n",
    "        def draw(index):\n",
    "            if not paused[0]:\n",
    "                t_index[0] = t_index[0] + (index - last_index[0])\n",
    "                t_index[0] = t_index[0] % len(poses)\n",
    "    \n",
    "            last_index[0] = index\n",
    "                \n",
    "            x, y, theta = poses[t_index[0]]\n",
    "            tr = Affine2D().rotate(theta).translate(x, y) + ax1.transData\n",
    "            \n",
    "            agent_patches = (body, line) + tuple(sensors) + tuple(motors)\n",
    "            \n",
    "            for patch in agent_patches:\n",
    "                patch.set_transform(tr);\n",
    "                \n",
    "            trail.set_data( poses[:t_index[0], 0], poses[:t_index[0], 1] )\n",
    "            \n",
    "            time = t_index[0] * self.dt\n",
    "            tracker.set_xdata([time, time])\n",
    "                \n",
    "            clock.set_text(\"Time: %.02f\" % time)\n",
    "                    \n",
    "            return (trail, light_r, light, clock, tracker) + agent_patches\n",
    "        \n",
    "        def init():\n",
    "            result = draw(0)\n",
    "            for artist in result:\n",
    "                if artist is not tracker:\n",
    "                    ax1.add_artist(artist)\n",
    "            return result\n",
    "    \n",
    "        def onclick(event):\n",
    "            if event.button == 1:\n",
    "                # pause if the user clicks on the main figure\n",
    "                if event.inaxes is ax1:\n",
    "                    paused[0] = not paused[0]\n",
    "                # edit time directly if the user clicks on the graph over time\n",
    "                elif event.inaxes is ax2:\n",
    "                    t_index[0] = (int) (event.xdata / self.dt)            \n",
    "            \n",
    "        def anim(index):\n",
    "            return draw(index)\n",
    "        \n",
    "        \n",
    "        ani = FuncAnimation(fig, anim, init_func=init, frames = None, interval=1000*self.dt/speedup, blit=True, save_count=len(poses))\n",
    "        \n",
    "        plt.show()\n",
    "    \n",
    "        fig.canvas.mpl_connect('button_press_event', onclick)\n",
    " \n",
    "        return ani            \n",
    "                                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function defines the circulatiry of a set of coordinates, the more circular a path, the more aimless\n",
    "# a search strategy appeasr to be, thus circularity is a good measure of purpose (or lack thereof)\n",
    "\n",
    "def circul(x,y,graph):\n",
    "\n",
    "    def x_y_tuple(x,y):\n",
    "        list_coords_tuple = []\n",
    "        for i in range(len(x)):\n",
    "            list_coords_tuple.append([x[i], y[i]])\n",
    "        return(list_coords_tuple)\n",
    "\n",
    "    def perim(points,graph):\n",
    "        hull = ConvexHull(points)\n",
    "        if graph ==1 :\n",
    "            plt.plot(points[:,0], points[:,1], 'o')\n",
    "            for simplex in hull.simplices:\n",
    "                plt.plot(points[simplex, 0], points[simplex, 1], 'r')\n",
    "        perimeter = hull.area\n",
    "        return(perimeter)\n",
    "    \n",
    "    def area_cal(pts):\n",
    "        hull = ConvexHull(pts) \n",
    "        area = hull.volume\n",
    "        return(area)\n",
    "    \n",
    "    pts = np.array(x_y_tuple(x,y))\n",
    "    perimeter = perim(pts,graph)\n",
    "    area = area_cal(pts)\n",
    "\n",
    "    circularity = 4*math.pi*area/((perimeter**2))\n",
    "    \n",
    "    return(area, perimeter, circularity)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here take two guassian curves and find their intersection distance (this is applied to the shortest line between the 2 3d curves)\n",
    "def solve(m1,m2,std1,std2):\n",
    "    a = 1/(2*std1**2) - 1/(2*std2**2)\n",
    "    b = m2/(std2**2) - m1/(std1**2)\n",
    "    c = m1**2 /(2*std1**2) - m2**2 / (2*std2**2) - np.log(std2/std1)\n",
    "    \n",
    "    return np.roots([a,b,c])\n",
    "\n",
    "# here we are taking the  guessed light position, the guessed dead reckoning location and using the sensor and motor noise as\n",
    "# staandard deviation, so the larger the noise the higher the uncertainty, the wider the guassian 'hill'\n",
    "\n",
    "def gaussian_intersection(light,motor,sensor_noise,motor_noise):\n",
    "    \n",
    "    # we find the shortest distance between the two guassian peaks with basic triganometry\n",
    "    \n",
    "    dist = np.sqrt((motor[0]-light[0])**2 + (motor[1]-light[1])**2) \n",
    "    \n",
    "    # send the distance through to find where the intesction point will be along this line\n",
    "    \n",
    "    mid = solve(0,dist,sensor_noise,motor_noise)\n",
    "    mid = [item for item in mid if item >= 0]\n",
    "    \n",
    "    # if lines overlap on both sides of a guasian peak this won't help, we only want to take the mid point between the guassian peaks\n",
    "    \n",
    "    mid = min(mid)\n",
    "    \n",
    "    # Figure out the mid point on the 2D plane\n",
    "\n",
    "    if motor[0] == light[0] and motor[1]>light[1]:\n",
    "        loc = [motor[0],light[1]+mid]\n",
    "    \n",
    "    if motor[0] == light[0] and light[1]>motor[1]:\n",
    "        loc = [motor[0],motor[1]+mid]\n",
    "        \n",
    "    if motor[1] == light[1] and motor[0]>light[0]:\n",
    "        loc = [light[0]+mid,motor[1]]\n",
    "    \n",
    "    if motor[1] == light[1] and light[0]>motor[0]:\n",
    "        loc = [motor[0]+mid,motor[1]]\n",
    "    \n",
    "    if motor[0] == light[0] and motor[1] == light[1]:\n",
    "        loc = [motor[0],light[0]]\n",
    "    \n",
    "    if motor[0] != light[0]:\n",
    "        x_dif = abs(motor[0]-light[0])\n",
    "        y_dif = abs(motor[1]-light[1])\n",
    "        \n",
    "        angle = np.arctan(y_dif/x_dif)\n",
    "    \n",
    "    if motor[0]>light[0] and motor[1]>light[1]:\n",
    "        loc = [light[0]+ mid*np.cos(angle),light[1]+ mid*np.sin(angle)]\n",
    "        \n",
    "    if motor[0]>light[0] and motor[1]<light[1]:\n",
    "        loc = [light[0]+ mid*np.cos(angle),light[1]- mid*np.sin(angle)]\n",
    "        \n",
    "    if motor[0]<light[0] and motor[1]<light[1]:\n",
    "        loc = [light[0]- mid*np.cos(angle),light[1]- mid*np.sin(angle)]\n",
    "        \n",
    "    if motor[0]<light[0] and motor[1]>light[1]:\n",
    "        loc = [light[0]- mid*np.cos(angle),light[1] + mid*np.sin(angle)] \n",
    "    \n",
    "    # Return these mid point coordinates as the new location\n",
    "\n",
    "    return(loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we are taking the sense data for the robot's 'spin in place' behaviour to treat the light like a cephid star\n",
    "# obiously we are moving and the lights luminosity is not changing, however we can use the oscillating light \n",
    "# as a guage of the light intensity minus noise, it isnt perfect but its fairly robust\n",
    "\n",
    "def cephid_star(sensations,sampling_size,theta,lum=1,r=0.5,height=-0.1):\n",
    "    \n",
    "    sensations = np.array(sensations)\n",
    "    t = np.linspace(0, sampling_size, sampling_size)\n",
    "\n",
    "    data = sensations[sampling_size:2*sampling_size - len(sensations)]\n",
    "    data = data.reshape(sampling_size,)\n",
    "\n",
    "    guess_mean = np.mean(data)\n",
    "    guess_std = np.std(data)/(2**0.5)/(2**0.5)\n",
    "    guess_phase = 0\n",
    "    guess_freq = 1\n",
    "    guess_amp = 0.5\n",
    "\n",
    "    data_first_guess = guess_std*np.sin(t+guess_phase) + guess_mean\n",
    "    optimize_func = lambda x: x[0]*np.sin(x[1]*t+x[2]) + x[3] - data\n",
    "    est_amp, est_freq, est_phase, est_mean = leastsq(optimize_func, [guess_amp, guess_freq, guess_phase, guess_mean])[0]\n",
    "    data_fit = est_amp*np.sin(est_freq*t+est_phase) + est_mean\n",
    "\n",
    "    fine_t = np.arange(0,max(t),0.1)\n",
    "    data_fit=est_amp*np.sin(est_freq*fine_t+est_phase)+est_mean\n",
    "    \n",
    "    max_light_reading = abs(max(data_fit))\n",
    "\n",
    "    distance = np.sqrt((lum/max_light_reading) - height**2 ) + r\n",
    "    \n",
    "    # Invert the light intesnsity and use the guessed angle provided by the controller at this stage to say where the light is\n",
    "\n",
    "    # Convert information from polar to cartesian coordinates \n",
    "    \n",
    "    lx = distance*np.cos(theta)\n",
    "    ly = distance*np.sin(theta)\n",
    "\n",
    "    return([lx,ly])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BTDR_Bayes(sensations_list, state, dt,motor_history,local_angle_history,self_location,target_angle,global_angle_history,reached,reached_home,slope_l,guess_angle):\n",
    "    \n",
    "    #here we can pick the sampling rate, for one full rotation it is about 31-31 timesteps so we will be safe and say 31\n",
    "    \n",
    "    sampling_size = 31\n",
    "    \n",
    "    if len(sensations_list) <= sampling_size: # so to get an idea of the sensor noise (standard deviation for the gaussian curve)\n",
    "                                              # lets sit in place for 31 timesteps and see what sensor variation we get\n",
    "        output = [0,0] \n",
    "        slope = 0 # we are going to say that the slope information is 0 because wee need a minimum of 31 sample size of our sense\n",
    "                  # data to get a graient with the code implemented, besides as this is noise determining behaviour, slope isnt important right now\n",
    "                \n",
    "    if len(sensations_list)>sampling_size: # okay now we have obtained sensory noise lets calculate the slope\n",
    "        \n",
    "        sensations_snip = (np.array(sensations_list[-sampling_size:])).reshape(sampling_size,)\n",
    "    \n",
    "        slope, intercept, r_value, p_value, std_err = stats.linregress(np.linspace(0,sampling_size,sampling_size),sensations_snip)\n",
    "        \n",
    "        # Here, the slope or gradient is used to integrate proior information to create a more informed threshold value for our 'Run' behaviour\n",
    "        \n",
    "        sensor_error = 3*(np.std(sensations_list[:sampling_size]))\n",
    "        \n",
    "        # Because motor noise and moving around will constantly change sensor readings we will keep the sensor error based on those first 31 points\n",
    "        # testing it out, it was found the standard deviation multiplied by 3 is roughly equivalent for sensory values\n",
    "        \n",
    "        output = [1,-1] # lets 'Tumble' and look for the angle ascosiated with the sharpest sensory gradient\n",
    "\n",
    "        counter = 0 # set a counter for our sampling\n",
    "        sense_max = -100 # set a sensory reading lower than possible \n",
    "        index_max = 0 # token that keeps track of highest gradient timestep in past 31\n",
    "        \n",
    "        for i in range(sampling_size-1): # 'Tumble'for one full rotation\n",
    "\n",
    "            if slope_l[-sampling_size:][i] >= sense_max: # If our gradient is high enough this will become the new timestamp to change our angle\n",
    "                sense_max = slope_l[-sampling_size:][i] # change the maximum gradient value to comapre against \n",
    "                \n",
    "                index_max = counter # counter to hold onto the local timestamp\n",
    "\n",
    "            counter+=1 # move onto next timestamp\n",
    "         \n",
    "        target_angle = local_angle_history[-sampling_size:][index_max] # of the past full rotation is this the highest gradient we found if so this becaomse the new target angle to rotate to\n",
    "        \n",
    "        if len(sensations_list) == sampling_size*2: # for our first rotation in place we note \n",
    "                                                    # down the angle that had the steepest graient for our photsensor based guess of where the light is\n",
    "            angle_guess = target_angle\n",
    "\n",
    "    angle_change = ((np.tanh(output[1])-np.tanh(output[0]))/(2*0.5)) # We update a local angle set as if we would keep spinning indefinitely, this allows us to make the choise to wither go forward or spin\n",
    "    new_angle = local_angle_history[-1] + angle_change*dt            # update the local angle history\n",
    "    \n",
    "   \n",
    "    if target_angle+0.75 >new_angle >target_angle-0.75 and (sampling_size*2)>len(sensations_list)>=sampling_size:\n",
    "        output = [1,-1] # This is for out cephid star stage, seeing what one cycle of spinning outputs as the light \n",
    "                        # intesnity of the light source\n",
    "            \n",
    "    if target_angle+0.75 >new_angle >target_angle-0.75 and len(sensations_list)>2*sampling_size:\n",
    "        output = [1,1] # if the theoretical next (local) angle matches the target angle derived above we move toward the light source\n",
    "\n",
    "    if reached == 1: # if the light source is percieved as reached we change our behaviour \n",
    "                \n",
    "        net_angle = ((global_angle_history[-1])%(2*math.pi)) # here we are finding the angle of orientation of the robot (where its front is facing)\n",
    "        home_angle = abs(np.arctan(self_location[-1][1]/self_location[-1][0])) # here we are finding the angle of the centre of the robot chissis is relative to its percieved start points\n",
    "        \n",
    "        if self_location[-1][1] >= 0 and  self_location[-1][0] > 0: # decide what angle we need to turn to to be facing home\n",
    "            targ = math.pi + home_angle\n",
    "            \n",
    "        if self_location[-1][1] < 0 and  self_location[-1][0] < 0:\n",
    "            targ = home_angle\n",
    "        \n",
    "        if self_location[-1][1] > 0 and  self_location[-1][0] < 0:\n",
    "            targ = 2*math.pi - home_angle\n",
    "            \n",
    "        if self_location[-1][1] < 0 and  self_location[-1][0] > 0:\n",
    "            targ = math.pi - home_angle\n",
    "        \n",
    "        if targ*1.1 > net_angle > targ*0.9:\n",
    "            output = [1,1] # lets head home\n",
    "                               \n",
    "        if targ*1.1 < net_angle or net_angle < targ*0.9:\n",
    "            output = [0,1] # let's turn around and face home based on above information\n",
    "        \n",
    "        if 0.5>output[0]>-0.5 and 0.5>output[1]>-0.5:\n",
    "            reached_home = 1 # if we percieve ourr cordinates are approximately zero lets change the 'reached home token'\n",
    "\n",
    "            \n",
    "    if reached_home == 1:\n",
    "        # if we have decided we have reached home lets shut off motors (this never happens in practice)\n",
    "\n",
    "        output =[0,0]\n",
    "        \n",
    "    \n",
    "    delta_angle = ((np.tanh(output[1])-np.tanh(output[0]))/(2*0.5)) # this notes the actual change in angle (instead of th etheoretical perpetual rotation we note what out motor outputs did)\n",
    "\n",
    "    real_new_angle = global_angle_history[-1] + delta_angle*dt # euler integrate our new angle\n",
    "    \n",
    "    hyp = (((np.tanh(output[1])+np.tanh(output[0]))/2))  # find out our journey linkage (how far we moved in this time step)\n",
    "\n",
    "    s_location = [(hyp*(np.cos(real_new_angle))*dt + self_location[-1][0]),(hyp*(np.sin(real_new_angle))*dt + self_location[-1][1])]\n",
    "    self_location.append(s_location) # lets integrate our knowledge of angle and journey linkage to update our idea of self location\n",
    "\n",
    "    local_angle_history.append(new_angle)\n",
    "    global_angle_history.append(real_new_angle) # update our angle history\n",
    "    \n",
    "    slope_l.append(slope) # update our list of gradient\n",
    "\n",
    "    if len(sensations_list) > sampling_size and slope>0.025 and reached == 0: # if our slope hits a certain threshold (this was trial and errored to find an appropriate value)\n",
    "        \n",
    "        # Okay, here we need to use senor and motor noise with percieved light and self location to update our knowledge of where we are for the return journey\n",
    "        \n",
    "        sensor_noise = sensor_error\n",
    "        motor_noise =0.1\n",
    "        guess_location = s_location\n",
    "        guess_light = cephid_star(sensations_list,sampling_size,guess_angle)\n",
    "        updated_location = gaussian_intersection(guess_light,guess_location,sensor_noise,motor_noise)\n",
    "        self_location.append(updated_location) # Add our bayesian inspired new location to act on for the return journey\n",
    "\n",
    "        reached = 1 # change our light reached token to reflect we think we have reached the light\n",
    "\n",
    "    return(output,local_angle_history,self_location,global_angle_history,reached,reached_home,slope_l,guess_angle,None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01057698]\n",
      "Fitness on task 1: -66.600000\n",
      "Fitness on task 2: -inf\n"
     ]
    }
   ],
   "source": [
    "# Do a trial run to see if everything works\n",
    "\n",
    "w = World(sensor_noise = 0.1,motor_noise=0.1)\n",
    "\n",
    "act_token = 0\n",
    "\n",
    "poses, sensations, actions, states,light_pos,light_poses,self_location,f_command = w.simulate(BTDR_Bayes,active_token=act_token)\n",
    "self_location=np.array(self_location)\n",
    "plt.ion()\n",
    "%matplotlib qt\n",
    "\n",
    "# Lets plot our outward and return jounrney ant style with our path integrated route home\n",
    "\n",
    "if np.isinf(w.task1fitness(poses)) ==True:\n",
    "    plt.plot(poses[:,0],poses[:,1],label = 'Outward Journey')\n",
    "    \n",
    "else:\n",
    "    plt.plot(poses[:int(-w.task1fitness(poses)*10)][:,0], poses[:int(-w.task1fitness(poses)*10)][:,1],c='b',label = 'Outward Journey')\n",
    "    plt.plot(poses[int(-w.task1fitness(poses)*10):][:,0], poses[int(-w.task1fitness(poses)*10):][:,1],c='r',label = 'Return Journey')\n",
    "\n",
    "if len(light_poses)>0:\n",
    "    plt.scatter((np.array(light_poses))[:,0],(np.array(light_poses))[:,1],c='y',label='decoy light')\n",
    "plt.scatter(light_pos[0], light_pos[1],c='r',s=100,label = 'Final_light')\n",
    "\n",
    "circ_num =circul(poses[:,0],poses[:,1],0)\n",
    "\n",
    "plt.title('Bacterial tumbling and dead reckoning (bayesian) \\n , path of robot \\n Circularity = '+str(round(circ_num[2],3)))\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "if act_token == 0:\n",
    "    str1 = 'Bacterial tumbling and dead reckoning  (bayesian)controller with decoys, path of robot'\n",
    "    \n",
    "if act_token == 2:\n",
    "    str1 = 'Bacterial tumbling and dead reckoning (bayesian)controller without decoys, path of robot'\n",
    "    \n",
    "if np.isinf(w.task1fitness(poses)) == False and np.isinf(w.task2fitness(poses)) == False:\n",
    "    str2 = 'success'\n",
    "    \n",
    "else:\n",
    "    str2 = 'Failure'\n",
    "plt.savefig(str1+str2)\n",
    "\n",
    "ani = w.animate(poses, sensations)\n",
    "\n",
    "print(\"Fitness on task 1: %f\" % w.task1fitness(poses))\n",
    "print(\"Fitness on task 2: %f\" % w.task2fitness(poses))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we can run the simulation many times to get a pcolor plot of successes with different levels of noise with \n",
    "# or without decoy lights\n",
    "\n",
    "def test_func(act_token):\n",
    "    \n",
    "    res = 20\n",
    "    \n",
    "    sens_vars = np.linspace(0.1,1,res)\n",
    "    mot_vars = np.linspace(0.1,1,res)\n",
    "    \n",
    "    results_outward =np.zeros((res,res))\n",
    "    results_return =np.zeros((res,res))\n",
    "\n",
    "    k = 0\n",
    "    for s in sens_vars:\n",
    "        l = 0 \n",
    "        for m in mot_vars:\n",
    "            w = World(sensor_noise =s,motor_noise=m)\n",
    "            \n",
    "            avg_o = 0\n",
    "            avg_r = 0\n",
    "            \n",
    "            for i in range(5):\n",
    "                \n",
    "                poses, sensations, actions,light_pos,light_poses,light_poses,self_location,f_command = w.simulate(BTDR_Bayes,active_token=act_token)\n",
    "                fit_1 = w.task1fitness(poses)\n",
    "                fit_2 = w.task2fitness(poses)\n",
    "    \n",
    "                if np.isinf(fit_1)==True:\n",
    "                    fit_1 = -1000\n",
    "                \n",
    "                if np.isinf(fit_2)==True:\n",
    "                    fit_2 = -1000\n",
    "                    \n",
    "                avg_r+=fit_2\n",
    "                avg_o+=fit_1\n",
    "                \n",
    "            results_outward[k][l] = avg_o/5\n",
    "            results_return[k][l] = avg_r/5\n",
    "            \n",
    "            l+=1\n",
    "            \n",
    "        k+=1 \n",
    "        clear_output()\n",
    "        print(k*100/(res),'% Complete')\n",
    "        \n",
    "\n",
    "    \n",
    "    fig, (ax0,ax1) = plt.subplots(1,2)\n",
    "\n",
    "    c = ax0.pcolor(sens_vars,mot_vars,results_outward, cmap='RdBu')\n",
    "    ax0.set_title('Outward journey successes')\n",
    "    ax0.set_xlabel('Motor Noise')\n",
    "    ax0.set_ylabel('Sensor Noise')\n",
    "    ax0.axis([0.1, 1, 0.1, 1])\n",
    "    fig.colorbar(c , ax=ax0)\n",
    "            \n",
    "    c = ax1.pcolor(sens_vars,mot_vars,results_return, cmap='RdBu')\n",
    "    ax1.set_title('Return journey successes')\n",
    "    ax1.set_xlabel('Motor Noise')\n",
    "    ax1.set_ylabel('Sensor Noise')\n",
    "    ax1.axis([0.1, 1, 0.1, 1])\n",
    "    fig.colorbar(c , ax=ax1)\n",
    "    \n",
    "    if act_token == 0 :\n",
    "        fig.suptitle('Bacterial tumbling with dead reckoning (bayesian) \\n performance (w/ Decoy light)')\n",
    "        fig.savefig('Bacterialtumblingwithdeadreckoningbayesianperformance(wDecoylight).PNG')\n",
    "    if act_token == 2 :\n",
    "        fig.suptitle('Bacterial tumbling with dead reckoning (bayesian) \\n performance (No decoy light)')\n",
    "        fig.savefig('Bacterialtumblingwithdeadreckoningbayesianperformance(NoDecoylight).PNG')\n",
    "\n",
    "test_func(0)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Mapping_controller_no_path_integration.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
