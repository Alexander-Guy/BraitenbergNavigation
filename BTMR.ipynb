{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s0zmqjwFCnKZ"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.linalg.linalg as LA\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.transforms import Affine2D\n",
    "import matplotlib.patches as patches\n",
    "from matplotlib.text import Annotation\n",
    "\n",
    "#from matplotlib.mlab import find\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import scipy.stats as stats\n",
    "from scipy.spatial import ConvexHull, convex_hull_plot_2d\n",
    "from scipy.spatial.distance import euclidean\n",
    "\n",
    "import math\n",
    "import random\n",
    "\n",
    "twoPi = np.pi * 2\n",
    "\n",
    "def find(condition):\n",
    "    res, = np.nonzero(np.ravel(condition))\n",
    "    return res\n",
    "\n",
    "class MultipleNRV(object):\n",
    "    \"\"\"Multiple independent normal random variables.\"\"\"\n",
    "    def __init__(self, size, loc=0., scale=1.):\n",
    "        self.size = size\n",
    "        self.mean, self.std = loc, scale\n",
    "        self.twoVariance = 2 * self.std ** 2\n",
    "    \n",
    "    def pdf(self, xs):\n",
    "        \"\"\"Returns the probability density function value for a particular\n",
    "        vector.\"\"\"\n",
    "        twoVar = self.twoVariance\n",
    "        if twoVar == 0:\n",
    "            return 1 if xs == self.mean else 0\n",
    "        else:\n",
    "            delta2 = (xs - self.mean) ** 2\n",
    "            return np.product( np.exp( -delta2 / twoVar ) / np.sqrt( twoVar * np.pi) )        \n",
    "            \n",
    "    def sample(self):\n",
    "        \"\"\"Returns a vector sampled from the PDF.\"\"\"\n",
    "        loc, scale, n = self.mean, self.std, self.size\n",
    "        return loc if scale == 0 else np.random.normal(loc, scale, size=self.size)                                                                        \n",
    "\n",
    "class World(object):\n",
    "    \n",
    "    def __init__(self, sensor_angles=(0,), luminance=1.0, light_coords=(10, 0, -0.1), v_max=1.0, agent_radius=0.5, sensor_noise=0, motor_noise=0, dt=0.1, seed=None):\n",
    "        self.sensors = np.array(sensor_angles)\n",
    "        self.light_pos = np.array(light_coords)\n",
    "        self.v_max = v_max\n",
    "        self.agent_radius = agent_radius\n",
    "        self.luminance = luminance\n",
    "        self.dt = dt\n",
    "        \n",
    "        if seed is not None:\n",
    "            np.random.seed(seed)\n",
    "\n",
    "        # set up noise random variables\n",
    "        sensor_sigma = sensor_noise * np.sqrt(dt)\n",
    "        motor_sigma = motor_noise * np.sqrt(dt)\n",
    "        \n",
    "\n",
    "        self.sensor_rv = MultipleNRV(size=len(sensor_angles), scale = sensor_sigma)\n",
    "        self.motor_rv = MultipleNRV(size=2, scale = motor_sigma)\n",
    "                \n",
    "    def sensor_pos(self, state):\n",
    "        \"\"\"Returns an array corresponding to a list of (x, y, 0) sensor \n",
    "        positions in world coordinates.\"\"\"\n",
    "        sensors, r = self.sensors, self.agent_radius\n",
    "        x, y, theta = state\n",
    "        n = len(sensors)\n",
    "        \n",
    "        result = np.zeros( (n, 3) )\n",
    "        # copy robot x, y into sensors\n",
    "        result[:,0:2] = state[0:2]\n",
    "        \n",
    "        angles = theta + sensors\n",
    "        result[:,0] = r * np.cos(angles) + x\n",
    "        result[:,1] = r * np.sin(angles) + y\n",
    "        \n",
    "        return result\n",
    "        \n",
    "    def sensor_input(self, state):\n",
    "        \"\"\"Returns an array of raw sensor input values for a particular\n",
    "        agent state (position and orientation). These are calculated\n",
    "        according to an inverse square distance law, and the agent's body\n",
    "        can occlude a sensor reducing its input to zero.\n",
    "        \"\"\"        \n",
    "        # various relevant parameters\n",
    "        r, K = self.agent_radius, self.luminance\n",
    "        # light position\n",
    "        l_pos = self.light_pos        \n",
    "\n",
    "        # unpack 3D position and heading from (x, y, theta) state\n",
    "        pos, theta = np.array(tuple(state[0:2]) + (0,)), state[-1]        \n",
    "\n",
    "        # positions in world coordinates of each sensor\n",
    "        s_pos = self.sensor_pos(state)\n",
    "        # array of distances of sensors from light source\n",
    "        d_s = LA.norm(l_pos - s_pos, axis=1)\n",
    "        \n",
    "        # distance of light from robot's centre\n",
    "        d_0 = LA.norm(l_pos - pos)\n",
    "\n",
    "        # array of zeros or ones for each sensor according to whether the \n",
    "        # agent's body lies between the sensor and the light source\n",
    "        not_occluded = (d_0**2 >= r**2 >= (d_s**2 - d_0**2))\n",
    "        \n",
    "        # light reaching each sensor\n",
    "        return not_occluded * K / d_s **2                \n",
    "        \n",
    "    def sensor_transform(self, activation):\n",
    "        \"\"\"Returns a vector of sensor readings for a particular sensor input \n",
    "        value (activation) vector. Noise is usually applied to the activation \n",
    "        before applying the transform.\"\"\"\n",
    "        # rescale to (0, 1) interval, assuming activation is positive\n",
    "        #return activation / (1 + activation)\n",
    "        K, l_pos = self.luminance, self.light_pos\n",
    "        # minimum distance is z coordinate of the light position\n",
    "        d_min = l_pos[-1]\n",
    "        \n",
    "        # rescale activation to range between 0 and a_max\n",
    "        # with midpoint around \n",
    "        a_max = K / ( d_min ** 2 )\n",
    "        a = a_max / (1 + np.exp(5*(K/4 - activation)))\n",
    "        \n",
    "        #return 1 / (1 + np.exp(-activation))\n",
    "        return activation\n",
    "        #return np.sqrt(K / a)\n",
    "    \n",
    "    def sensor_inverse_transform(self, reading):\n",
    "        \"\"\"Returns the vector of sensor input values (activations) that would be \n",
    "        needed to produce the specified sensor reading. \"\"\"\n",
    "        return reading / (1 - reading)\n",
    "    \n",
    "    \n",
    "    def sense(self, state):\n",
    "        \"\"\"Returns a vector of sensor reading values for a \n",
    "        particular agent state (position and orientation). \n",
    "        Noise is added to the raw luminance at the sensor's location\n",
    "        and the result is rescaled to the (0, 1) interval.\n",
    "        \"\"\"\n",
    "        activation = self.sensor_input(state) + self.sensor_rv.sample()\n",
    "                        \n",
    "        # and rescale to (0, 1) interval\n",
    "        return self.sensor_transform(activation)\n",
    "    \n",
    "    def p_sensation(self, state, sensation):\n",
    "        \"\"\"Returns a probability density value for the likelihood of a \n",
    "        particular sensor reading vector given a particular agent state.\"\"\"\n",
    "        # invert rescaling operation to find the original activations \n",
    "        sensor_activation = self.sensor_inverse_transform(sensation)\n",
    "        # determine the actual luminance at the sensors\n",
    "        sensor_input = self.sensor_input(state)        \n",
    "        \n",
    "        # interrogate the RV object to get the PDF value\n",
    "        return self.sensor_rv.pdf(sensor_input - sensor_activation)        \n",
    "\n",
    "    def act(self, state, action):\n",
    "        \"\"\"Applies a motor activation vector to an agent state, and simulates \n",
    "        the consequences using Euler integration over a dt interval.\"\"\"\n",
    "        # noisily map the action values to a (-1, +1) interval\n",
    "        motor_out = self.v_max * np.tanh(action) + self.motor_rv.sample()\n",
    "        \n",
    "        # calculate the linear speed and angular speed\n",
    "        v = motor_out.mean()\n",
    "        omega = (motor_out[1] - motor_out[0]) / (2.0 * self.agent_radius)\n",
    "        \n",
    "        # calculate time derivative of state\n",
    "        theta = state[-1]\n",
    "        deriv = [ v * np.cos(theta), v * np.sin(theta), omega ]\n",
    "        \n",
    "        # perform Euler integration\n",
    "        return self.dt * np.array(deriv) + state              \n",
    "        \n",
    "    # Function for changing the light position, here we can take the light, move it for N timestamps (in this case 100 or 10 seconds) and move it back\n",
    "    def light_change(self,original_state,active_token,stamp,light_poses):\n",
    "        \n",
    "        if active_token == 2: # If the token given is 2 initially we won't get a light change\n",
    "            pass\n",
    "        \n",
    "        if active_token == 0: # change light from its intiailised location to a random point along the x=10 axis, as it was found, too far away from the light,t he robot will nto get distracted\n",
    "            original_state = self.light_pos # initialisied light location for replacement\n",
    "            light_coords = [10,random.uniform(-5,5),-0.1]\n",
    "            self.light_pos = np.array(light_coords) # officially change light position in simulation\n",
    "            new_active_token = 1 #change token for next round\n",
    "            light_poses.append(light_coords) # add new coordinates to light locations\n",
    "\n",
    "            \n",
    "        if active_token == 1: # if the light had been moved here we move the light back to its initialised location\n",
    "            self.light_pos = original_state # officially change light location in code\n",
    "            new_active_token = 0 # change our token back\n",
    "            self.luminance = 1 \n",
    "\n",
    "        stamp = stamp + 100\n",
    "   \n",
    "        return(original_state,new_active_token,stamp,light_poses,self.light_pos)        \n",
    "        \n",
    "    def simulate(self, controller,active_token, interval=500.0):\n",
    "        \"\"\"Simulates the agent-environment system for the specified interval\n",
    "        (in simulated time units) starting from a random state. Returns\n",
    "        a (poses, sensations, actions, states) tuple where poses is a time array \n",
    "        of agent poses (position and orientation), sensations is a time array of \n",
    "        sensory readings, actions is a time array of motor activations, and\n",
    "        states is a list of arbitrary internal controller state objects.\n",
    "        \n",
    "        Must be called with a controller function of the form \n",
    "        controller(sensation, state, dt) that returns a (action, state) tuple\n",
    "        outputting motor activations and updated internal state in\n",
    "        response to sensor readings.\n",
    "        \"\"\"\n",
    "        poses = [ self.random_state() ]\n",
    "\n",
    "        states = [ None ]\n",
    "        sensations = [ ]\n",
    "        actions = [ ]\n",
    "        \n",
    "        reached_source = 0 # here we indicate that we have reached the light source, in BTDR variations of th code we have\n",
    "                           # a 'reached home' token but with motor reverse we have no ieda of our bearings\n",
    "\n",
    "        motor_history = [] # lets give a motor history we can use to reverse our path after we are done\n",
    "        \n",
    "        original_state = self.light_pos # set our light home positions so we can move it temporarily and back\n",
    "        \n",
    "        light_poses = [] # list to keep track of new light positions for plotting\n",
    "        \n",
    "        stamp = 0 # timestamp is a placeholder that allows us to move the light for a specific number of time\n",
    "\n",
    "        for i in range(int( interval / self.dt )):\n",
    "            \n",
    "            if i%1000 == 0 and active_token == 0:# here every 100 seconds the light will move \n",
    "                original_state,active_token,stamp,light_poses,self.light_pos = self.light_change(original_state,active_token,i,light_poses)\n",
    "                \n",
    "            if stamp == i  and active_token == 1:# here we call and move the light back when the allotted decoy time is up\n",
    "                original_state,active_token,stamp,light_poses,self.light_pos = self.light_change(original_state,active_token,i,light_poses)\n",
    "\n",
    "            \n",
    "            sensations.append(self.sense(poses[-1])) \n",
    "            action, motor_history, reached_source,state = controller(sensations[-1], states[-1], self.dt,sensations,reached_source,motor_history) ###############\n",
    "            actions.append(action)\n",
    "            states.append(state)\n",
    "            poses.append(self.act(poses[-1], actions[-1]))\n",
    "\n",
    "        return np.array(poses), np.array(sensations), np.array(actions), states,self.light_pos,light_poses \n",
    "    \n",
    "            \n",
    "        \n",
    "    def random_state(self):\n",
    "        \"\"\"Returns a random initial state.\"\"\"\n",
    "        result = np.zeros(3)\n",
    "        result[-1] = np.random.rand() * twoPi\n",
    "\n",
    "        return result\n",
    "        \n",
    "        \n",
    "    def task1fitness(self, poses):\n",
    "        \"\"\"Returns the fitness of the trajectory described by poses on \n",
    "        assignment task 1 (reaching the light source).\"\"\"\n",
    "        return -self.reached_light_at(poses)\n",
    "        \n",
    "    def task2fitness(self, poses):\n",
    "        \"\"\"Returns the fitness of the trajectory described by poses on \n",
    "        assignment task 1 (reaching the light source and returning to base).\"\"\"\n",
    "        light_time = self.reached_light_at(poses)\n",
    "        if light_time == np.inf:\n",
    "            return -np.inf\n",
    "        return -self.first_reached(poses, np.array([0, 0]), after=light_time) \n",
    "        \n",
    "    def first_reached(self, poses, xy, after = 0, within = 1.5):\n",
    "        after_index = int(np.floor(after / self.dt))\n",
    "        ds = LA.norm(xy - poses[after_index:,0:2], axis=1)\n",
    "        indices = np.nonzero(ds < within)[0]\n",
    "        \n",
    "        if len(indices) == 0:\n",
    "            return np.inf\n",
    "        \n",
    "        return (indices[0] + after_index) * self.dt\n",
    "        \n",
    "    def reached_light_at(self, poses):\n",
    "        return self.first_reached(poses, self.light_pos[0:2])\n",
    "    \n",
    "    \n",
    "    def animate(self, poses, sensations, speedup=5):\n",
    "        r, l_pos = self.agent_radius, self.light_pos\n",
    "        x, y, theta = poses[0]\n",
    "        \n",
    "        # use an Ellipse to visually represent the agent's body\n",
    "        body = patches.Ellipse(xy=(0, 0), width=2 * r, height=2 * r, fc='w', ec='k')\n",
    "        # use a black dot to visually represent each sensor\n",
    "        sensors = [ patches.Ellipse(xy=(r * np.cos(theta), r * np.sin(theta)), width=0.2, height=0.2, fc='b') for theta in self.sensors ]\n",
    "        # use small rectangles to visually represent the motors\n",
    "        motors = [ patches.Rectangle((-0.5*r, y), width = r, height = 0.2*r, color=\"black\") for y in (-1.1*r, 0.9*r) ]\n",
    "        # use a line to indicate the agent's orientation\n",
    "        line = Line2D( (x, x + r * np.cos(theta)), (y, y + r * np.sin(theta)) )\n",
    "        line = Line2D( (0, r), (0, 0) )\n",
    "        # draw a line showing the agent's \"trail\"\n",
    "        trail = Line2D( [], [], color='r') \n",
    "        # display a clock\n",
    "        clock = Annotation('', (0.8, 0.9), xycoords='axes fraction')    \n",
    "        # use a yellow circle to visually represent the light\n",
    "        light_r = patches.Ellipse(xy=l_pos[0:2], width=1, height=1, fc='y', ec='none')\n",
    "        light = patches.Ellipse(xy=l_pos[0:2], width=0.25, height=0.25, fc='b')\n",
    "        \n",
    "        fig, (ax1, ax2) = plt.subplots(2, 1, gridspec_kw = {'height_ratios': [10, 1] } )\n",
    "        ax1.axis(\"equal\")\n",
    "        ax1.set_xlim([-15, 15])\n",
    "        ax1.set_ylim([-15, 15])\n",
    "        ax1.set_title(\"Click On Main Display To Pause / Unpause\")\n",
    "        \n",
    "        ax2.set_title(\"Click On Sensor Graph To Change Time\")\n",
    "        \n",
    "        tracker = ax2.axvline(0, 0, 1)\n",
    "        paused = [ False ]\n",
    "        last_index = [ -1 ]\n",
    "        t_index = [ 0 ]\n",
    "        \n",
    "        if sensations is not None:\n",
    "            times = np.arange(0, self.dt * len(sensations), self.dt)\n",
    "            # plot the sensor values\n",
    "            ax2.plot(times, sensations, 'k');\n",
    "            # plot the ideal (noiseless) sensor values\n",
    "            ideal = np.array([self.sensor_transform(self.sensor_input(pose)) for pose in poses[:-1]])\n",
    "            ax2.plot(times, ideal, 'r')\n",
    "    \n",
    "        def draw(index):\n",
    "            if not paused[0]:\n",
    "                t_index[0] = t_index[0] + (index - last_index[0])\n",
    "                t_index[0] = t_index[0] % len(poses)\n",
    "    \n",
    "            last_index[0] = index\n",
    "                \n",
    "            x, y, theta = poses[t_index[0]]\n",
    "            tr = Affine2D().rotate(theta).translate(x, y) + ax1.transData\n",
    "            \n",
    "            agent_patches = (body, line) + tuple(sensors) + tuple(motors)\n",
    "            \n",
    "            for patch in agent_patches:\n",
    "                patch.set_transform(tr);\n",
    "                \n",
    "            trail.set_data( poses[:t_index[0], 0], poses[:t_index[0], 1] )\n",
    "            \n",
    "            time = t_index[0] * self.dt\n",
    "            tracker.set_xdata([time, time])\n",
    "                \n",
    "            clock.set_text(\"Time: %.02f\" % time)\n",
    "                    \n",
    "            return (trail, light_r, light, clock, tracker) + agent_patches\n",
    "        \n",
    "        def init():\n",
    "            result = draw(0)\n",
    "            for artist in result:\n",
    "                if artist is not tracker:\n",
    "                    ax1.add_artist(artist)\n",
    "            return result\n",
    "    \n",
    "        def onclick(event):\n",
    "            if event.button == 1:\n",
    "                # pause if the user clicks on the main figure\n",
    "                if event.inaxes is ax1:\n",
    "                    paused[0] = not paused[0]\n",
    "                # edit time directly if the user clicks on the graph over time\n",
    "                elif event.inaxes is ax2:\n",
    "                    t_index[0] = (int) (event.xdata / self.dt)            \n",
    "            \n",
    "        def anim(index):\n",
    "            return draw(index)\n",
    "        \n",
    "        \n",
    "        ani = FuncAnimation(fig, anim, init_func=init, frames = None, interval=1000*self.dt/speedup, blit=True, save_count=len(poses))\n",
    "        \n",
    "        plt.show()\n",
    "    \n",
    "        fig.canvas.mpl_connect('button_press_event', onclick)\n",
    "            \n",
    "        return ani            \n",
    "                                                  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function defines the circulatiry of a set of coordinates, the more circular a path, the more aimless\n",
    "# a search strategy appeasr to be, thus circularity is a good measure of purpose (or lack thereof)\n",
    "\n",
    "def circul(x,y,graph):\n",
    "\n",
    "    def x_y_tuple(x,y):\n",
    "        list_coords_tuple = []\n",
    "        for i in range(len(x)):\n",
    "            list_coords_tuple.append([x[i], y[i]])\n",
    "        return(list_coords_tuple)\n",
    "\n",
    "    def perim(points,graph):\n",
    "        hull = ConvexHull(points)\n",
    "        if graph ==1 :\n",
    "            plt.plot(points[:,0], points[:,1], 'o')\n",
    "            for simplex in hull.simplices:\n",
    "                plt.plot(points[simplex, 0], points[simplex, 1], 'r')\n",
    "        perimeter = hull.area\n",
    "        return(perimeter)\n",
    "    \n",
    "    def area_cal(pts):\n",
    "        hull = ConvexHull(pts) \n",
    "        area = hull.volume\n",
    "        return(area)\n",
    "    \n",
    "    pts = np.array(x_y_tuple(x,y))\n",
    "    perimeter = perim(pts,graph)\n",
    "    area = area_cal(pts)\n",
    "\n",
    "    circularity = 4*math.pi*area/((perimeter**2))\n",
    "    \n",
    "    return(area, perimeter, circularity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 316
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1895,
     "status": "ok",
     "timestamp": 1583429806121,
     "user": {
      "displayName": "Alexander Guy",
      "photoUrl": "",
      "userId": "04377543698005839283"
     },
     "user_tz": 0
    },
    "id": "qcZvatbQCnKe",
    "outputId": "132b2c36-3e38-44e3-c323-cd88c40921b0",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitness on task 1: -inf\n",
      "Fitness on task 2: -inf\n"
     ]
    }
   ],
   "source": [
    "def BTMR(sensors, state, dt,sensations_list,reached,motor_history):\n",
    "    \n",
    "        if len(sensations_list) > 50 and sensations_list[-1] > 4*sum(sensations_list[:45]) and reached == 0:\n",
    "            reached = 1 # After an arbitrary time period has occured and the threshold value is met we say we have arrived\n",
    "                        # at location, here the threshold is 4 times the sum of the first 45 timesteps which is about 1.5 turns \n",
    "                        # this was found to be a satisfactory value though doesnt adapt to changing circumstances\n",
    "\n",
    "        if reached == 0: # If we havent reached our target (the light) we implment our 'tumble/run' behaviour\n",
    "\n",
    "            threshold_value = 0.01 # through trial and error this local threshold was found to be satisfactory for a range of sensor noise\n",
    "                                   # though once again, it doesnt change to adapting circumstances\n",
    "\n",
    "\n",
    "            if sensors[0]<threshold_value: # If our threshold value isnt met by the sensors we Tumble\n",
    "                output = [(6),(-6)]\n",
    "\n",
    "            else : \n",
    "                output = [5,5] # if it is met we 'Run'\n",
    "                \n",
    "            motor_history.append(output) # Keep track of our motor actions\n",
    "                \n",
    "        else :\n",
    "\n",
    "            if len(motor_history)<1 : # If we have reversed all our motor steps, spiral out in the hopes we find home\n",
    "\n",
    "                output = [3*(len(sensations_list))/(100),1]\n",
    "\n",
    "            else: # while the motor history list isnt empty we\n",
    "\n",
    "                output =[-motor_history[-1][0],-motor_history[-1][1]] # do teh inverse of the most recent motor command\n",
    "\n",
    "                motor_history = motor_history[:-1] # remove this command from the list\n",
    "\n",
    "        return (output, motor_history,reached,None)     \n",
    "\n",
    "    \n",
    "# Test it out\n",
    "w = World(sensor_noise =0.3,motor_noise=0.3)\n",
    "\n",
    "act_token = 0\n",
    "\n",
    "poses, sensations, actions, states,light_pos,light_poses = w.simulate(BTMR,active_token=act_token)\n",
    "\n",
    "print(\"Fitness on task 1: %f\" % w.task1fitness(poses))\n",
    "print(\"Fitness on task 2: %f\" % w.task2fitness(poses))\n",
    "\n",
    "plt.ion()\n",
    "%matplotlib qt\n",
    "\n",
    "if np.isinf(w.task1fitness(poses)) ==True:\n",
    "    plt.plot(poses[:,0],poses[:,1],label = 'Outward Journey')\n",
    "    \n",
    "else:\n",
    "    plt.plot(poses[:int(-w.task1fitness(poses)*10)][:,0], poses[:int(-w.task1fitness(poses)*10)][:,1],c='b',label = 'Outward Journey')\n",
    "    plt.plot(poses[int(-w.task1fitness(poses)*10):][:,0], poses[int(-w.task1fitness(poses)*10):][:,1],c='r',label = 'Return Journey')\n",
    "\n",
    "if len(light_poses)>0:\n",
    "    plt.scatter((np.array(light_poses))[:,0],(np.array(light_poses))[:,1],c='y',label='decoy light')\n",
    "\n",
    "plt.scatter(light_pos[0], light_pos[1],c='r',s=100,label = 'Final_light')\n",
    "\n",
    "circ_num =circul(poses[:,0],poses[:,1],0)\n",
    "\n",
    "\n",
    "plt.title('Bacterial tumbling and reverse motor controller, path of robot \\n Circularity = '+str(round(circ_num[2],3)))\n",
    "plt.legend(fontsize=10)\n",
    "\n",
    "if act_token == 0:\n",
    "    str1 = 'Bacterial tumbling and reverse motor controller with decoys, path of robot'\n",
    "    \n",
    "if act_token == 2:\n",
    "    str1 = 'Bacterial tumbling and reverse motor controller without decoys, path of robot'\n",
    "    \n",
    "if np.isinf(w.task1fitness(poses)) == False and np.isinf(w.task2fitness(poses)) == False:\n",
    "    str2 = 'success'\n",
    "else:\n",
    "    str2 = 'Failure'\n",
    "plt.savefig(str1+str2)\n",
    "\n",
    "ani = w.animate(poses, sensations)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sTWVzlx9CnKh"
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-17fb4caa0acd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuptitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Bacterial tumbling with reverse motor command performance (No decoy light)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Bacterialtumblingwithreversemotorcommandperformance(Nodecoylight).PNG'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m \u001b[0mtest_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-17fb4caa0acd>\u001b[0m in \u001b[0;36mtest_func\u001b[0;34m(act_token)\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m                 \u001b[0mposes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msensations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlight_pos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlight_poses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimulate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBTMR\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mactive_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mact_token\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m                 \u001b[0mfit_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask1fitness\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mposes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m                 \u001b[0mfit_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask2fitness\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mposes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-e7e952865fed>\u001b[0m in \u001b[0;36msimulate\u001b[0;34m(self, controller, active_token, interval)\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m             \u001b[0msensations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mposes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m             \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmotor_history\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreached_source\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontroller\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msensations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msensations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreached_source\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmotor_history\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m###############\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m             \u001b[0mactions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-e7e952865fed>\u001b[0m in \u001b[0;36msense\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mand\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mrescaled\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthe\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0minterval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \"\"\"\n\u001b[0;32m--> 138\u001b[0;31m         \u001b[0mactivation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msensor_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msensor_rv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;31m# and rescale to (0, 1) interval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-e7e952865fed>\u001b[0m in \u001b[0;36msensor_input\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0ms_pos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msensor_pos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;31m# array of distances of sensors from light source\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         \u001b[0md_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml_pos\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0ms_pos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0;31m# distance of light from robot's centre\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mnorm\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36mnorm\u001b[0;34m(x, ord, axis, keepdims)\u001b[0m\n\u001b[1;32m   2511\u001b[0m             \u001b[0;31m# special case for speedup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2512\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2513\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeepdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2514\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2515\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Here we can run the simulation many times to get a pcolor plot of successes with different levels of noise with \n",
    "# or without decoy lights (please be aware this may take some time to run ~ 40 Minutes)\n",
    "\n",
    "def test_func(act_token):\n",
    "    \n",
    "    res = 20\n",
    "    \n",
    "    sens_vars = np.linspace(0.1,1,res)\n",
    "    mot_vars = np.linspace(0.1,1,res)\n",
    "    \n",
    "    results_outward =np.zeros((res,res))\n",
    "    results_return =np.zeros((res,res))\n",
    "\n",
    "    k = 0\n",
    "    for s in sens_vars:\n",
    "        l = 0 \n",
    "        for m in mot_vars:\n",
    "            w = World(sensor_noise =s,motor_noise=m)\n",
    "            \n",
    "            avg_o = 0\n",
    "            avg_r = 0\n",
    "            \n",
    "            for i in range(5):\n",
    "                \n",
    "                poses, sensations, actions, states,light_pos,light_poses = w.simulate(BTMR,active_token=act_token)\n",
    "                fit_1 = w.task1fitness(poses)\n",
    "                fit_2 = w.task2fitness(poses)\n",
    "    \n",
    "                if np.isinf(fit_1)==True:\n",
    "                    fit_1 = -1000\n",
    "                \n",
    "                if np.isinf(fit_2)==True:\n",
    "                    fit_2 = -1000\n",
    "                    \n",
    "                avg_r+=fit_2\n",
    "                avg_o+=fit_1\n",
    "                \n",
    "            results_outward[k][l] = avg_o/5\n",
    "            results_return[k][l] = avg_r/5\n",
    "            \n",
    "            l+=1\n",
    "        k+=1\n",
    "        \n",
    "        clear_output()\n",
    "        print(k*100/(res),'% Complete')\n",
    "\n",
    "    \n",
    "    fig, (ax0,ax1) = plt.subplots(1,2)\n",
    "\n",
    "    c = ax0.pcolor(sens_vars,mot_vars,results_outward, cmap='RdBu')\n",
    "    ax0.set_title('Outward journey successes')\n",
    "    ax0.set_xlabel('Motor Noise')\n",
    "    ax0.set_ylabel('Sensor Noise')\n",
    "    ax0.axis([0.1, 1, 0.1, 1])\n",
    "    fig.colorbar(c , ax=ax0)\n",
    "            \n",
    "    c = ax1.pcolor(sens_vars,mot_vars,results_return, cmap='RdBu')\n",
    "    ax1.set_title('Return journey successes')\n",
    "    ax1.set_xlabel('Motor Noise')\n",
    "    ax1.set_ylabel('Sensor Noise')\n",
    "    ax1.axis([0.1, 1, 0.1, 1])\n",
    "    fig.colorbar(c , ax=ax1)\n",
    "    \n",
    "    if act_token == 0 :\n",
    "        fig.suptitle('Bacterial tumbling with reverse motor command performance (w/ Decoy light)')\n",
    "        fig.savefig('Bacterialtumblingwithreversemotorcommandperformance(wDecoylight).PNG')\n",
    "        \n",
    "    if act_token == 2 :\n",
    "        fig.suptitle('Bacterial tumbling with reverse motor command performance (No decoy light)')\n",
    "        fig.savefig('Bacterialtumblingwithreversemotorcommandperformance(Nodecoylight).PNG')\n",
    "test_func(0)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_func(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Assignment 1_Dumb_controller_no_path_integration.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
